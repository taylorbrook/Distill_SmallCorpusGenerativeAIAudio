---
phase: 16-full-pipeline-integration
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/distill/models/persistence.py
  - src/distill/inference/chunking.py
  - src/distill/inference/generation.py
  - src/distill/inference/blending.py
  - src/distill/cli/generate.py
  - src/distill/ui/tabs/library_tab.py
  - src/distill/training/loop.py
  - src/distill/training/checkpoint.py
autonomous: true
requirements: [INTEG-01, INTEG-02, INTEG-05]
must_haves:
  truths:
    - "Generating audio from a trained v2.0 model produces a waveform via ISTFT"
    - "Exported audio plays back correctly in all formats (WAV/MP3/FLAC/OGG)"
    - "CLI and UI generation workflows produce audio without errors"
    - "A v2.0 model saved and reloaded produces identical audio output"
  artifacts:
    - path: "src/distill/models/persistence.py"
      provides: "LoadedModel with ComplexSpectrogram and norm_stats for ISTFT"
      contains: "ComplexSpectrogram"
    - path: "src/distill/inference/chunking.py"
      provides: "2-channel overlap-add synthesis returning [1, 2, n_mels, total_frames]"
      contains: "complex_mel_to_waveform"
    - path: "src/distill/inference/generation.py"
      provides: "ISTFT waveform generation replacing NotImplementedError stubs"
      contains: "complex_mel_to_waveform"
  key_links:
    - from: "src/distill/inference/chunking.py"
      to: "ComplexSpectrogram.complex_mel_to_waveform"
      via: "spectrogram.complex_mel_to_waveform(combined_mel, stats=norm_stats)"
      pattern: "complex_mel_to_waveform"
    - from: "src/distill/models/persistence.py"
      to: "saved model .distill file"
      via: "norm_stats stored in saved dict and restored on load"
      pattern: "normalization_stats"
    - from: "src/distill/inference/generation.py"
      to: "src/distill/inference/chunking.py"
      via: "generate_chunks_crossfade/latent_interp return np.ndarray audio"
      pattern: "generate_chunks"
---

<objective>
Wire the ISTFT generation pipeline through model persistence, chunking, and generation so that all audio generation produces waveforms via ComplexSpectrogram.complex_mel_to_waveform.

Purpose: Replace all NotImplementedError stubs in the generation path with working ISTFT reconstruction. This is the critical path -- without it, no audio can be generated from v2.0 models.

Output: Generation pipeline produces playable audio from trained models via CLI and UI.
</objective>

<execution_context>
@C:/Users/Taylor/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/Taylor/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/15-istft-reconstruction/15-01-SUMMARY.md
@.planning/phases/15-istft-reconstruction/15-02-SUMMARY.md
@.planning/phases/12-2-channel-data-pipeline/12-01-SUMMARY.md

<interfaces>
<!-- Key types and contracts the executor needs. Extracted from codebase. -->

From src/distill/audio/spectrogram.py:
```python
class ComplexSpectrogram:
    def __init__(self, config: "ComplexSpectrogramConfig") -> None: ...
    def complex_mel_to_waveform(
        self,
        spectrogram: "torch.Tensor",  # [B, 2, n_mels, time]
        stats: dict[str, float] | None = None,
        sample_rate: int = 48_000,
    ) -> "torch.Tensor":  # [B, 1, samples]
        """Reconstruct audio waveform from 2-channel magnitude + IF spectrogram."""
    def to(self, device: "torch.device") -> "ComplexSpectrogram": ...
```

From src/distill/training/config.py:
```python
@dataclass
class ComplexSpectrogramConfig:
    if_masking_threshold: float = 1e-5
    n_fft: int = 2048
    hop_length: int = 512
    n_mels: int = 128
```

From src/distill/models/persistence.py:
```python
@dataclass
class LoadedModel:
    model: "ConvVAE"
    spectrogram: "AudioSpectrogram"
    analysis: "AnalysisResult | None"
    metadata: ModelMetadata
    device: "torch.device"

def save_model(model, spectrogram_config, training_config, metadata, models_dir, analysis=None) -> Path: ...
def load_model(model_path, device="cpu") -> LoadedModel: ...
def save_model_from_checkpoint(checkpoint_path, metadata, models_dir) -> Path: ...
```

From src/distill/inference/chunking.py:
```python
def synthesize_continuous_mel(model, spectrogram, latent_trajectory, chunk_samples=48_000) -> torch.Tensor:
    """Returns [1, 1, n_mels, total_frames] -- NEEDS UPDATE to [1, 2, n_mels, total_frames]"""

def generate_chunks_crossfade(model, spectrogram, num_chunks, device, seed, chunk_samples, overlap_samples) -> np.ndarray: ...
def generate_chunks_latent_interp(model, spectrogram, num_chunks, device, seed, chunk_samples, steps_between) -> np.ndarray: ...
```

norm_stats dict format (from preprocessing):
```python
norm_stats = {
    "mag_mean": float,
    "mag_std": float,
    "if_mean": float,
    "if_std": float,
}
```
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add norm_stats and ComplexSpectrogram to model persistence</name>
  <files>
    src/distill/models/persistence.py
    src/distill/training/loop.py
    src/distill/training/checkpoint.py
  </files>
  <action>
**Goal:** Persist normalization statistics with the saved model so ComplexSpectrogram.complex_mel_to_waveform can denormalize at inference time. Also create and attach a ComplexSpectrogram to LoadedModel.

**persistence.py changes:**

1. Add `complex_spectrogram: "ComplexSpectrogram | None"` and `normalization_stats: dict | None` fields to `LoadedModel` dataclass (after `device` field). Keep backward compatibility -- both default to `None`.

2. In `save_model()`:
   - Add `normalization_stats: dict | None = None` parameter (after `analysis`).
   - Add `"normalization_stats": normalization_stats` to the `saved` dict (after `"metadata"`).

3. In `load_model()`:
   - After reconstructing `AudioSpectrogram`, also construct a `ComplexSpectrogram`:
     ```python
     from distill.audio.spectrogram import ComplexSpectrogram
     from distill.training.config import ComplexSpectrogramConfig
     complex_spec = ComplexSpectrogram(ComplexSpectrogramConfig())
     complex_spec.to(torch_device)
     ```
   - Extract `normalization_stats = saved.get("normalization_stats")`.
   - Pass both to the returned `LoadedModel`:
     ```python
     complex_spectrogram=complex_spec,
     normalization_stats=normalization_stats,
     ```

4. In `save_model_from_checkpoint()`:
   - Extract `normalization_stats = checkpoint.get("normalization_stats")` from checkpoint.
   - Pass `normalization_stats=normalization_stats` to the `save_model()` call.

**loop.py changes:**

5. In `train()`, pass `norm_stats` to the `save_model()` call (around line 793):
   ```python
   saved_model_path = save_model(
       model=model,
       spectrogram_config=asdict(spec_config),
       training_config=asdict(config),
       metadata=metadata,
       models_dir=models_dir,
       analysis=analysis_result,
       normalization_stats=norm_stats,  # NEW
   )
   ```

**checkpoint.py changes:**

6. In `save_checkpoint()`:
   - Add `normalization_stats: dict | None = None` parameter.
   - Add `"normalization_stats": normalization_stats` to the checkpoint dict.

7. Back in loop.py, in `_save_checkpoint_safe()` and its caller, pass `norm_stats` through to `save_checkpoint()`. Find the `_save_checkpoint_safe` function and add the parameter there too.

**v1.0 model error message (per CONTEXT.md locked decision):**

8. In `load_model()`, update the error message at line 300 (the format marker check) from:
   ```python
   raise ValueError(f"Not a valid .distill model file: {model_path}")
   ```
   to:
   ```python
   raise ValueError("Incompatible model format. Please retrain with current version.")
   ```
   This is the exact message specified in CONTEXT.md for when an incompatible (v1.0) model is detected.

**Important:** For old models saved without normalization_stats, `load_model` should still work -- `saved.get("normalization_stats")` returns `None`, and `LoadedModel.normalization_stats` defaults to `None`. This is the v1.0 model error case -- those models can't generate audio, which is the intended behavior (clean break per CONTEXT.md: "v1.0 models will not load at all"). v1.0 models won't have the format marker, so they'll hit the updated error message above. No special handling needed.
  </action>
  <verify>
    <automated>cd H:/dev/Distill-complex-spec && python -c "
from distill.models.persistence import LoadedModel
print('LoadedModel has complex_spectrogram:', hasattr(LoadedModel, '__dataclass_fields__') and 'complex_spectrogram' in LoadedModel.__dataclass_fields__)
print('LoadedModel has normalization_stats:', 'normalization_stats' in LoadedModel.__dataclass_fields__)

# Verify v1.0 error message matches CONTEXT.md decision
import inspect, re
from distill.models import persistence
src = inspect.getsource(persistence.load_model)
assert 'Incompatible model format. Please retrain with current version.' in src, 'Error message not updated to match CONTEXT.md decision'
print('v1.0 error message matches CONTEXT.md decision: True')
"</automated>
  </verify>
  <done>LoadedModel has complex_spectrogram and normalization_stats fields. save_model accepts normalization_stats parameter. load_model constructs ComplexSpectrogram and extracts normalization_stats from saved dict. Checkpoints also persist normalization_stats.</done>
</task>

<task type="auto">
  <name>Task 2: Wire ISTFT reconstruction into chunking and generation pipeline</name>
  <files>
    src/distill/inference/chunking.py
    src/distill/inference/generation.py
    src/distill/inference/blending.py
    src/distill/cli/generate.py
    src/distill/ui/tabs/library_tab.py
  </files>
  <action>
**Goal:** Replace all NotImplementedError stubs in chunking.py and generation.py with working ISTFT reconstruction via ComplexSpectrogram.complex_mel_to_waveform.

**chunking.py -- Fix synthesize_continuous_mel for 2-channel:**

The current code at line 274 does `mel_2d = mel.squeeze(0).squeeze(0).cpu()` which drops both batch and channel dims. For 2-channel `[1, 2, n_mels, time]` output from `model.decode`, this would produce `[n_mels, time]` instead of `[2, n_mels, time]`.

1. Change `synthesize_continuous_mel` to handle 2-channel:
   - Determine `n_channels` from the first decoded mel (decode one to check): `n_channels = mel.shape[1]` (will be 2 for v2.0 models).
   - Change `output` shape from `(n_mels, total_frames)` to `(n_channels, n_mels, total_frames)`.
   - Change `mel_2d` extraction to `mel.squeeze(0).cpu()` (squeeze only batch dim, keep channels): shape `[C, n_mels, chunk_frames]`.
   - Window application: `output[:, :, start:end] += mel_2d * window.unsqueeze(0).unsqueeze(0)` (broadcast window over channels and mels).
   - Normalization: `output = output / norm.unsqueeze(0).unsqueeze(0)` (broadcast over channels and mels).
   - Return: `output.unsqueeze(0)` giving `[1, C, n_mels, total_frames]`.
   - Also fix single-step case (line 254): the `.cpu()` return is already fine since it returns `[1, 2, n_mels, time]` from `model.decode`.
   - Update the docstring: return shape is `[1, C, n_mels, total_frames]` where C=2 for v2.0 models.

**chunking.py -- Wire generate_chunks_crossfade (around line 429):**

Replace the TODO stub + NotImplementedError with:
```python
# Convert 2-channel mel spectrogram to waveform via ISTFT
wav = spectrogram.complex_mel_to_waveform(combined_mel)
return wav.squeeze().numpy().astype(np.float32)
```

Here `spectrogram` is the function parameter. **BUT** -- this is currently typed as `AudioSpectrogram` which does NOT have `complex_mel_to_waveform`. The callers (in generation.py) pass `self.spectrogram` which comes from `LoadedModel.spectrogram`.

**Solution:** The chunking functions should accept a `complex_spectrogram` parameter for ISTFT conversion. But changing all signatures is invasive. Instead, since `LoadedModel` now has `complex_spectrogram`, the callers in generation.py should pass it.

**Better solution:** Since the `spectrogram` parameter is only used for `get_mel_shape()` in the chunking functions (and for the old mel_to_waveform which is gone), change the approach:
- Add `complex_spectrogram` parameter to `generate_chunks_crossfade`, `generate_chunks_latent_interp`, and `_generate_chunks_from_vector`. Default `None` for backward compat.
- Add `normalization_stats: dict | None = None` parameter too (needed for denormalization).
- In the ISTFT wiring: `wav = complex_spectrogram.complex_mel_to_waveform(combined_mel, stats=normalization_stats)`.

2. Update `generate_chunks_crossfade` signature:
   - Add `complex_spectrogram=None` and `normalization_stats: dict | None = None` parameters.
   - Replace the NotImplementedError stub with:
     ```python
     wav = complex_spectrogram.complex_mel_to_waveform(combined_mel, stats=normalization_stats)
     return wav.squeeze().numpy().astype(np.float32)
     ```

3. Update `generate_chunks_latent_interp` signature the same way and wire identically.

**generation.py -- Wire _generate_chunks_from_vector (around line 339):**

4. Add `complex_spectrogram=None` and `normalization_stats: dict | None = None` parameters.
5. Replace the NotImplementedError stub with same pattern:
   ```python
   wav = complex_spectrogram.complex_mel_to_waveform(combined_mel, stats=normalization_stats)
   return wav.squeeze().numpy().astype(np.float32)
   ```

**generation.py -- Update GenerationPipeline:**

6. Add `complex_spectrogram` and `normalization_stats` to `GenerationPipeline.__init__`:
   ```python
   def __init__(self, model, spectrogram, device, complex_spectrogram=None, normalization_stats=None):
       self.model = model
       self.spectrogram = spectrogram
       self.device = device
       self.complex_spectrogram = complex_spectrogram
       self.normalization_stats = normalization_stats
       self.model_name = "unknown"
   ```

7. In `GenerationPipeline.generate()`, pass `complex_spectrogram` and `normalization_stats` to all chunk generation calls:
   - `_generate_chunks_from_vector(..., complex_spectrogram=self.complex_spectrogram, normalization_stats=self.normalization_stats)`
   - `generate_chunks_crossfade(..., complex_spectrogram=self.complex_spectrogram, normalization_stats=self.normalization_stats)`
   - `generate_chunks_latent_interp(..., complex_spectrogram=self.complex_spectrogram, normalization_stats=self.normalization_stats)`

8. In `_generate_right_channel`, pass the same parameters through to the three generation function calls.

**Update callers that create GenerationPipeline:**

9. In generation.py itself, update _generate_right_channel to pass through complex_spectrogram and normalization_stats.

10. The callers that create GenerationPipeline (in CLI generate.py, UI library_tab.py, blending.py) need to pass the new params. Find all `GenerationPipeline(` calls:
    - `src/distill/cli/generate.py` line ~531: `GenerationPipeline(loaded.model, loaded.spectrogram, torch_device)` -> add `complex_spectrogram=loaded.complex_spectrogram, normalization_stats=loaded.normalization_stats`
    - `src/distill/ui/tabs/library_tab.py` line ~160: same pattern
    - `src/distill/inference/blending.py` lines ~554, ~675, ~721: same pattern using `slot.` prefix (the slot gets its data from LoadedModel -- the ModelSlot also needs updating)

**BUT WAIT** -- to keep this plan to 2 tasks, let me scope this more carefully. The blending.py and UI/CLI caller updates are mechanical 1-line additions. Include them in this task since they're necessary for the generation pipeline to work end-to-end.

For blending.py, `ModelSlot` has `spectrogram: AudioSpectrogram`. Add `complex_spectrogram: "ComplexSpectrogram | None" = None` and `normalization_stats: dict | None = None` fields. Update `add_model` to accept and pass them. Update the 3 `GenerationPipeline(...)` calls in blending.py to pass them through.

For CLI generate.py, update the `GenerationPipeline(loaded.model, loaded.spectrogram, torch_device)` call to include the new params.

For UI library_tab.py, same update to the `GenerationPipeline(...)` call.
  </action>
  <verify>
    <automated>cd H:/dev/Distill-complex-spec && python -c "
from distill.inference.chunking import generate_chunks_crossfade, generate_chunks_latent_interp
from distill.inference.generation import GenerationPipeline, _generate_chunks_from_vector
import inspect
sig_cf = inspect.signature(generate_chunks_crossfade)
sig_li = inspect.signature(generate_chunks_latent_interp)
sig_gv = inspect.signature(_generate_chunks_from_vector)
sig_gp = inspect.signature(GenerationPipeline.__init__)
print('crossfade has complex_spectrogram:', 'complex_spectrogram' in sig_cf.parameters)
print('latent_interp has complex_spectrogram:', 'complex_spectrogram' in sig_li.parameters)
print('generate_from_vector has complex_spectrogram:', 'complex_spectrogram' in sig_gv.parameters)
print('GenerationPipeline has complex_spectrogram:', 'complex_spectrogram' in sig_gp.parameters)
print('No NotImplementedError in generation pipeline')
"</automated>
  </verify>
  <done>All NotImplementedError stubs in chunking.py and generation.py replaced with working ISTFT reconstruction. synthesize_continuous_mel handles 2-channel spectrograms. GenerationPipeline and all callers (CLI, UI, blending) pass ComplexSpectrogram and normalization_stats through.</done>
</task>

</tasks>

<verification>
1. `python -c "from distill.models.persistence import LoadedModel; print(LoadedModel.__dataclass_fields__.keys())"` shows complex_spectrogram and normalization_stats
2. `python -c "from distill.inference.generation import GenerationPipeline"` imports without error
3. No remaining `NotImplementedError` stubs in generation.py or chunking.py: `grep -n "NotImplementedError" src/distill/inference/generation.py src/distill/inference/chunking.py` returns 0 results
4. `python -m pytest tests/test_istft_reconstruction.py -x` still passes (existing ISTFT tests)
</verification>

<success_criteria>
- LoadedModel carries ComplexSpectrogram and normalization_stats from persistence
- synthesize_continuous_mel produces [1, 2, n_mels, total_frames] for 2-channel models
- All 3 chunking/generation functions call complex_mel_to_waveform with norm_stats
- GenerationPipeline.__init__ accepts and passes complex_spectrogram and normalization_stats
- All callers (CLI, UI, blending) updated to pass new params
- Zero NotImplementedError stubs remain in chunking.py and generation.py
</success_criteria>

<output>
After completion, create `.planning/phases/16-full-pipeline-integration/16-01-SUMMARY.md`
</output>
