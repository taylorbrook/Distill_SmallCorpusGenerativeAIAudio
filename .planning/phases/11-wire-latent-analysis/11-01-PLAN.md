---
phase: 11-wire-latent-analysis
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/small_dataset_audio/training/loop.py
  - src/small_dataset_audio/training/checkpoint.py
  - src/small_dataset_audio/ui/tabs/generate_tab.py
autonomous: true
gap_closure: true

must_haves:
  truths:
    - "LatentSpaceAnalyzer.analyze() runs automatically after training completes (normal completion only, not cancellation)"
    - "Analysis result is serialized and stored in the final checkpoint dict under 'latent_analysis' key"
    - "train() returns analysis result in its result dict so callers have immediate access"
    - "Analysis failure logs a warning but does not crash training or prevent model saving"
    - "UI generate tab and blend dropdown use correct attribute name (metadata.name, entry.name) instead of nonexistent model_name"
  artifacts:
    - path: "src/small_dataset_audio/training/loop.py"
      provides: "Post-training latent space analysis in the finalize section"
      contains: "LatentSpaceAnalyzer"
    - path: "src/small_dataset_audio/training/checkpoint.py"
      provides: "Optional latent_analysis field in save_checkpoint"
      contains: "latent_analysis"
    - path: "src/small_dataset_audio/ui/tabs/generate_tab.py"
      provides: "Fixed metadata attribute references"
      contains: "metadata.name"
  key_links:
    - from: "src/small_dataset_audio/training/loop.py"
      to: "src/small_dataset_audio/controls/analyzer.py"
      via: "LatentSpaceAnalyzer.analyze() call after final checkpoint save"
      pattern: "analyzer\\.analyze"
    - from: "src/small_dataset_audio/training/loop.py"
      to: "src/small_dataset_audio/training/checkpoint.py"
      via: "save_checkpoint with latent_analysis parameter"
      pattern: "latent_analysis="
    - from: "src/small_dataset_audio/training/loop.py"
      to: "src/small_dataset_audio/controls/serialization.py"
      via: "analysis_to_dict() to serialize analysis for checkpoint"
      pattern: "analysis_to_dict"
---

<objective>
Wire LatentSpaceAnalyzer into the training loop so analysis runs automatically after training completes, persist analysis in checkpoints, and fix the pre-existing metadata.model_name bug.

Purpose: This is the foundational wiring that all downstream flows (CLI auto-save, UI save-to-library) depend on. Once analysis lives in the checkpoint, save_model_from_checkpoint() automatically picks it up without additional changes. The bug fix eliminates AttributeError crashes in the generate tab.

Output: Modified training loop that runs analysis post-training, checkpoint format that carries analysis, and bug-free UI attribute references.
</objective>

<execution_context>
@/Users/taylorbrook/.claude/get-shit-done/workflows/execute-plan.md
@/Users/taylorbrook/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/11-wire-latent-analysis/11-RESEARCH.md
@src/small_dataset_audio/training/loop.py
@src/small_dataset_audio/training/checkpoint.py
@src/small_dataset_audio/controls/analyzer.py
@src/small_dataset_audio/controls/serialization.py
@src/small_dataset_audio/training/dataset.py
@src/small_dataset_audio/ui/tabs/generate_tab.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Wire analysis into training loop and checkpoint persistence</name>
  <files>
    src/small_dataset_audio/training/loop.py
    src/small_dataset_audio/training/checkpoint.py
  </files>
  <action>
**checkpoint.py changes:**

Add an optional `latent_analysis` parameter to `save_checkpoint()`:
- Add `latent_analysis: dict | None = None` as the last parameter in the function signature.
- Include `"latent_analysis": latent_analysis` in the checkpoint dict (after "metrics_history" key on ~line 104).
- Update the docstring to document the new parameter.
- No changes to `load_checkpoint()` -- callers use `checkpoint.get("latent_analysis")` which already works for both old (missing key) and new (has key) checkpoints.

**loop.py changes (Finalize section, after `_save_checkpoint_safe` call at ~line 606, before completion event at ~line 616):**

1. Add post-training analysis block. The analysis runs between the final checkpoint save and the TrainingCompleteEvent. Insert after `manage_checkpoints` (line 613) and before "Emit completion event" comment (line 615):

```python
# Run latent space analysis
analysis_result = None
try:
    from small_dataset_audio.controls.analyzer import LatentSpaceAnalyzer
    from small_dataset_audio.controls.serialization import analysis_to_dict
    from small_dataset_audio.training.dataset import AudioTrainingDataset
    from torch.utils.data import DataLoader as TorchDataLoader

    logger.info("Running latent space analysis...")
    analyzer = LatentSpaceAnalyzer()

    # Use ALL training files (not split) for maximum PCA coverage
    analysis_dataset = AudioTrainingDataset(
        file_paths=file_paths,
        chunk_samples=int(1.0 * 48_000),
        augmentation_pipeline=None,
    )
    analysis_loader = TorchDataLoader(
        analysis_dataset,
        batch_size=config.batch_size,
        shuffle=False,
        num_workers=0,
    )

    analysis_result = analyzer.analyze(
        model=model,
        dataloader=analysis_loader,
        spectrogram=spectrogram,
        device=device,
    )
    logger.info(
        "Analysis complete: %d active components, %.1f%% variance explained",
        analysis_result.n_active_components,
        sum(analysis_result.explained_variance_ratio) * 100,
    )

    # Re-save the final checkpoint WITH analysis included
    analysis_dict = analysis_to_dict(analysis_result)
    _save_checkpoint_safe(
        checkpoint_dir, model, optimizer, scheduler, final_epoch, 0,
        final_train, final_val, final_kl, config, spec_config, metrics_history,
        latent_analysis=analysis_dict,
    )
except Exception:
    logger.warning("Latent space analysis failed -- model saved without analysis", exc_info=True)
```

2. Update `_save_checkpoint_safe()` to accept and forward `latent_analysis`:
- Add `latent_analysis: dict | None = None` parameter after `metrics_history`.
- Pass `latent_analysis=latent_analysis` in the `save_checkpoint()` call inside the try block.

3. Add `"analysis"` key to the return dict at the end of the finalize section (line 634): `"analysis": analysis_result`.

4. Do NOT add analysis to the cancellation return paths (the two early returns around lines 468 and 588). Per research decision: no analysis on cancelled training.

**Critical implementation notes:**
- All imports inside the try block (lazy import pattern).
- `num_workers=0` on the analysis DataLoader to avoid multiprocessing issues at end of training.
- `augmentation_pipeline=None` -- analysis uses raw, unaugmented data.
- The re-save of the final checkpoint overwrites the one saved moments earlier, now with analysis.
- The `analysis_result` variable is initialized to `None` before the try block so the return dict always has the key.
  </action>
  <verify>
Grep `src/small_dataset_audio/training/loop.py` for "LatentSpaceAnalyzer" -- must appear in the finalize section. Grep `src/small_dataset_audio/training/checkpoint.py` for "latent_analysis" -- must appear in save_checkpoint signature and checkpoint dict. Grep loop.py return dict for `"analysis"` key. Verify `_save_checkpoint_safe` has `latent_analysis` parameter.
  </verify>
  <done>
`train()` runs `LatentSpaceAnalyzer.analyze()` after final checkpoint save on normal completion. Analysis result is serialized via `analysis_to_dict()` and stored in the final checkpoint. The result dict returned by `train()` includes `analysis` key. Analysis failure is caught and logged without crashing. Cancellation paths do NOT run analysis.
  </done>
</task>

<task type="auto">
  <name>Task 2: Fix metadata.model_name attribute bug in generate_tab.py</name>
  <files>
    src/small_dataset_audio/ui/tabs/generate_tab.py
  </files>
  <action>
Fix all incorrect `model_name` attribute references in `generate_tab.py`. The `ModelMetadata` dataclass (in `models/persistence.py`) uses `name`, not `model_name`. The `ModelEntry` dataclass (in `library/catalog.py`) also uses `name`, not `model_name`.

Three locations to fix:

1. **Line 276** in `_generate_audio()` -- history entry:
   Change `app_state.loaded_model.metadata.model_name` to `app_state.loaded_model.metadata.name`.

2. **Line 346** in `_export_audio()` -- export metadata:
   Change `app_state.loaded_model.metadata.model_name` to `app_state.loaded_model.metadata.name`.

3. **Line 539** in `_refresh_blend_model_choices()` -- blend dropdown:
   Change `e.model_name` to `e.name`.

Each is a simple string replacement. No logic changes needed.
  </action>
  <verify>
Run `grep -n "model_name" src/small_dataset_audio/ui/tabs/generate_tab.py` -- the only remaining occurrences should be the `model_name=` keyword argument on function calls (e.g., `model_name=app_state.loaded_model.metadata.name`), NOT `.metadata.model_name` or `e.model_name` attribute accesses. Specifically, zero occurrences of `.model_name` as an attribute access on metadata or entry objects.
  </verify>
  <done>
All three `model_name` attribute bugs are fixed to use the correct `name` field. No more `AttributeError` when generating, exporting, or listing blend models from the UI.
  </done>
</task>

</tasks>

<verification>
1. `save_checkpoint()` in checkpoint.py accepts `latent_analysis` parameter
2. `_save_checkpoint_safe()` in loop.py forwards `latent_analysis` parameter
3. `train()` finalize section calls `LatentSpaceAnalyzer.analyze()` wrapped in try/except
4. `train()` re-saves final checkpoint with analysis dict after successful analysis
5. `train()` return dict includes `"analysis"` key (None if analysis failed or was skipped)
6. Cancellation paths do NOT call analyzer
7. `generate_tab.py` has zero occurrences of `.model_name` as attribute access
8. No import-time heavy imports added (all lazy inside function bodies)
</verification>

<success_criteria>
- LatentSpaceAnalyzer.analyze() called automatically in train() finalize section
- Analysis serialized and stored in final checkpoint via analysis_to_dict()
- train() result dict has "analysis" key accessible by callers (CLI, UI)
- Analysis failure produces warning log, not crash
- All metadata.model_name / e.model_name bugs fixed to .name
</success_criteria>

<output>
After completion, create `.planning/phases/11-wire-latent-analysis/11-01-SUMMARY.md`
</output>
