---
phase: 11-wire-latent-analysis
plan: 02
type: execute
wave: 2
depends_on: ["11-01"]
files_modified:
  - src/small_dataset_audio/cli/train.py
  - src/small_dataset_audio/cli/generate.py
autonomous: true
gap_closure: true

must_haves:
  truths:
    - "CLI train command auto-saves the best checkpoint as a .sda model to the library after successful training"
    - "CLI train shows the saved model path, name, and ID in output"
    - "CLI train does NOT auto-save on cancellation (exit code 3)"
    - "CLI generate supports --slider INDEX:VALUE for direct slider control"
    - "CLI --slider converts to latent vector via sliders_to_latent() and passes to GenerationConfig"
    - "CLI --slider gracefully handles missing analysis (warning, falls back to random)"
  artifacts:
    - path: "src/small_dataset_audio/cli/train.py"
      provides: "Auto-save model after training with --model-name override"
      contains: "save_model_from_checkpoint"
    - path: "src/small_dataset_audio/cli/generate.py"
      provides: "Slider option for direct slider position control"
      contains: "--slider"
  key_links:
    - from: "src/small_dataset_audio/cli/train.py"
      to: "src/small_dataset_audio/models/persistence.py"
      via: "save_model_from_checkpoint() with best checkpoint path"
      pattern: "save_model_from_checkpoint"
    - from: "src/small_dataset_audio/cli/generate.py"
      to: "src/small_dataset_audio/controls/mapping.py"
      via: "sliders_to_latent() converting --slider args to latent vector"
      pattern: "sliders_to_latent"
---

<objective>
Wire CLI train command to auto-save trained models to the library and add --slider support to CLI generate for direct slider position control.

Purpose: Closes the two remaining integration gaps: CLI train currently finishes without saving to the model library (user has no .sda file), and CLI generate has no way to specify slider positions directly (only via presets). After this plan, the full CLI workflow is: train -> model saved automatically -> generate with sliders.

Output: Modified CLI train with auto-save and --model-name option. Modified CLI generate with --slider INDEX:VALUE option.
</objective>

<execution_context>
@/Users/taylorbrook/.claude/get-shit-done/workflows/execute-plan.md
@/Users/taylorbrook/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/11-wire-latent-analysis/11-RESEARCH.md
@.planning/phases/11-wire-latent-analysis/11-01-SUMMARY.md
@src/small_dataset_audio/cli/train.py
@src/small_dataset_audio/cli/generate.py
@src/small_dataset_audio/models/persistence.py
@src/small_dataset_audio/controls/mapping.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add auto-save model to CLI train command</name>
  <files>
    src/small_dataset_audio/cli/train.py
  </files>
  <action>
**Add --model-name option to train_cmd:**

Add a new parameter after `json_output`:
```python
model_name: Annotated[
    Optional[str],
    typer.Option("--model-name", help="Name for saved model (default: dataset_name_timestamp)"),
] = None,
```

**Add auto-save after successful training (in the "Post-training output" section, AFTER the cancellation check but BEFORE "Build result summary"):**

Insert a new section between the cancellation check (`raise typer.Exit(code=3)`) and the result summary build:

```python
# ------------------------------------------------------------------
# Auto-save model to library
# ------------------------------------------------------------------
best_checkpoint = result.get("best_checkpoint_path")
if best_checkpoint is not None:
    from small_dataset_audio.models.persistence import ModelMetadata, save_model_from_checkpoint

    # Generate model name: user override or dataset_name_timestamp
    if model_name:
        auto_name = model_name
    else:
        from datetime import datetime
        ts = datetime.now().strftime("%Y%m%d_%H%M%S")
        auto_name = f"{dataset_dir.name}_{ts}"

    meta = ModelMetadata(
        name=auto_name,
        dataset_name=dataset_dir.name,
        dataset_file_count=len(file_paths),
        training_date=datetime.now().strftime("%Y-%m-%dT%H:%M:%S"),
    )

    try:
        models_base = resolve_path(
            app_config["paths"].get("models", "data/models"),
            base_dir=config_path.parent,
        )
        models_base.mkdir(parents=True, exist_ok=True)

        model_path = save_model_from_checkpoint(
            checkpoint_path=best_checkpoint,
            metadata=meta,
            models_dir=models_base,
        )
        console.print(f"\n[bold green]Model saved to library![/bold green]")
        console.print(f"  Name: {auto_name}")
        console.print(f"  Path: {model_path}")
        console.print(f"  ID:   {meta.model_id}")
    except Exception as exc:
        console.print(f"\n[yellow]Warning:[/yellow] Failed to auto-save model: {exc}")
        logger.warning("Auto-save model failed", exc_info=True)
```

Note: `datetime` is already imported at the top of the function body. The `resolve_path` import is already present. The `save_model_from_checkpoint` function in persistence.py already reads `checkpoint.get("latent_analysis")` and includes it in the saved model -- so the analysis from Plan 11-01 flows through automatically.

**Update the result summary** to include model save info:

Add `"model_path"` and `"model_name"` keys to the `result_summary` dict:
```python
"model_path": str(model_path) if best_checkpoint else None,
"model_name": auto_name if best_checkpoint else None,
```

Note: Use a variable `saved_model_path` defined before the try/except (initialized to None) to safely reference in the summary.

**Update the human-readable output** (the `else` branch of `if json_output:`) to show model info:
```python
if saved_model_path:
    console.print(f"  Model:          {saved_model_path}")
```
  </action>
  <verify>
Grep `src/small_dataset_audio/cli/train.py` for "save_model_from_checkpoint" -- must appear. Grep for "--model-name" -- must appear in parameter definition. Verify the auto-save is placed AFTER cancellation check and BEFORE result summary. Verify auto-save is wrapped in try/except.
  </verify>
  <done>
CLI `sda train` auto-saves the best checkpoint as a .sda model to the library after successful training. Default name is `{dataset_name}_{timestamp}`, overridable via `--model-name`. Model path, name, and ID are shown in console output and included in JSON output. Auto-save failure logs a warning but does not crash the CLI. Cancelled training (exit code 3) does NOT auto-save.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add --slider support to CLI generate command</name>
  <files>
    src/small_dataset_audio/cli/generate.py
  </files>
  <action>
**Add --slider option to generate() function signature:**

Add after the `preset` parameter (before `output_dir`):
```python
slider: Annotated[
    Optional[list[str]],
    typer.Option(
        "--slider",
        help="Set slider position as INDEX:VALUE (e.g., --slider '0:5' --slider '1:-3'). Range: -10 to 10.",
    ),
] = None,
```

**Add slider processing in the single-model generation path (after preset handling, before `gen_config = GenerationConfig(...)`):**

Insert after the preset loading block (after line ~461, before `gen_config = GenerationConfig(...)` at line ~463):

```python
# Handle --slider option (direct slider position control)
if slider is not None and latent_vector is None:
    if loaded.analysis is None:
        console.print(
            "[yellow]Warning:[/yellow] Model has no latent analysis. "
            "--slider ignored, using random latent vectors."
        )
    else:
        from small_dataset_audio.controls.mapping import (
            SliderState,
            sliders_to_latent,
        )

        n_active = loaded.analysis.n_active_components
        positions = [0] * n_active  # default to center (neutral)

        for s in slider:
            if ":" not in s:
                raise typer.BadParameter(
                    f"Invalid slider format '{s}'. Expected INDEX:VALUE (e.g., '0:5')"
                )
            idx_str, val_str = s.split(":", 1)
            try:
                idx = int(idx_str)
                val = int(val_str)
            except ValueError:
                raise typer.BadParameter(
                    f"Invalid slider values in '{s}'. INDEX and VALUE must be integers."
                )
            if idx < 0 or idx >= n_active:
                raise typer.BadParameter(
                    f"Slider index {idx} out of range. Model has {n_active} active components (0-{n_active - 1})."
                )
            if val < -10 or val > 10:
                raise typer.BadParameter(
                    f"Slider value {val} out of range. Must be between -10 and 10."
                )
            positions[idx] = val

        slider_state = SliderState(positions=positions, n_components=n_active)
        latent_vector = sliders_to_latent(slider_state, loaded.analysis)
        console.print(
            f"[green]Sliders applied:[/green] {len(slider)} position(s) set"
        )
```

Note: The `SliderState` and `sliders_to_latent` imports may already exist from the preset block above. The lazy import inside the conditional is fine (project pattern). If both `--preset` and `--slider` are provided, preset takes priority (slider is skipped because `latent_vector` is already set from preset). This is handled by the `latent_vector is None` guard.

**Also add slider support to the blend mode path** (or document that sliders are for single-model only). For simplicity, add a note that --slider is ignored in blend mode. Add after the `if blend:` block start (~line 310):

```python
if slider is not None:
    console.print(
        "[yellow]Warning:[/yellow] --slider is not supported with --blend. "
        "Using neutral slider positions for blend."
    )
```
  </action>
  <verify>
Grep `src/small_dataset_audio/cli/generate.py` for "--slider" -- must appear in the option definition. Grep for "sliders_to_latent" -- must appear in the slider processing block. Grep for "SliderState" -- must appear. Verify that slider parsing validates INDEX range (0 to n_active-1) and VALUE range (-10 to 10).
  </verify>
  <done>
CLI `sda generate MODEL --slider 0:5 --slider 1:-3` sets specific slider positions for generation. Slider positions are validated against model's active component count and the -10 to 10 range. Missing analysis produces a warning and falls back to random latent vectors. Preset takes priority over sliders if both provided. Blend mode warns that sliders are not supported.
  </done>
</task>

</tasks>

<verification>
1. `sda train DATASET --model-name "my model"` would auto-save to library after training
2. `sda train DATASET` generates a default name like `{dataset_name}_{timestamp}`
3. Cancelled training (Ctrl-C) exits with code 3 and does NOT auto-save
4. Auto-save failure is caught and logged, does not crash CLI
5. `sda generate MODEL --slider 0:5 --slider 1:-3` applies slider positions
6. `sda generate MODEL --preset X --slider 0:5` uses preset (slider ignored since latent already set)
7. `sda generate MODEL --slider 0:5` with no analysis warns and uses random vectors
8. Invalid slider format/range raises BadParameter error
9. JSON output from train includes model_path and model_name
</verification>

<success_criteria>
- CLI train auto-saves best checkpoint as .sda model after successful training
- Default model name is dataset_name_timestamp, overridable via --model-name
- CLI generate accepts --slider INDEX:VALUE for direct slider position control
- Slider validation checks index bounds, value range, and format
- All integration gaps (3 and 5) are closed
- Full CLI workflow works: train -> auto-save -> generate with sliders
</success_criteria>

<output>
After completion, create `.planning/phases/11-wire-latent-analysis/11-02-SUMMARY.md`
</output>
