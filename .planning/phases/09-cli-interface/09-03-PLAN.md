---
phase: 09-cli-interface
plan: 03
type: execute
wave: 2
depends_on: ["09-01"]
files_modified:
  - src/small_dataset_audio/cli/train.py
  - src/small_dataset_audio/cli/__init__.py
autonomous: true

must_haves:
  truths:
    - "User can train a model from CLI with `sda train DATASET_DIR`"
    - "Training shows Rich progress bar with epoch/loss/val_loss/ETA"
    - "Ctrl+C during training saves checkpoint gracefully and exits with code 3"
    - "User can select training preset (conservative/balanced/aggressive/auto) via --preset"
    - "User can override individual training params (--epochs, --lr, --batch-size)"
    - "Training results (output dir, best checkpoint) printed on completion"
  artifacts:
    - path: "src/small_dataset_audio/cli/train.py"
      provides: "sda train command with Rich progress, SIGINT handling, preset+override config"
      contains: "def train"
  key_links:
    - from: "src/small_dataset_audio/cli/train.py"
      to: "src/small_dataset_audio/training/loop.py"
      via: "Direct call to train() function (NOT TrainingRunner)"
      pattern: "from small_dataset_audio.training.loop import train"
    - from: "src/small_dataset_audio/cli/train.py"
      to: "src/small_dataset_audio/training/config.py"
      via: "TrainingConfig and get_adaptive_config for preset selection"
      pattern: "get_adaptive_config|TrainingConfig"
    - from: "src/small_dataset_audio/cli/train.py"
      to: "src/small_dataset_audio/training/metrics.py"
      via: "EpochMetrics and TrainingCompleteEvent for callback dispatch"
      pattern: "EpochMetrics|TrainingCompleteEvent"
---

<objective>
Implement the `sda train` CLI command with Rich progress bars, SIGINT graceful cancellation, training preset selection, and individual parameter overrides.

Purpose: Enables headless/scripted model training from the terminal, which is essential for remote/server workflows and automated training pipelines.
Output: Working `sda train DATASET_DIR` command with full training lifecycle.
</objective>

<execution_context>
@/Users/taylorbrook/.claude/get-shit-done/workflows/execute-plan.md
@/Users/taylorbrook/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/09-cli-interface/09-CONTEXT.md
@.planning/phases/09-cli-interface/09-RESEARCH.md
@.planning/phases/09-cli-interface/09-01-SUMMARY.md
@src/small_dataset_audio/cli/__init__.py
@src/small_dataset_audio/training/loop.py
@src/small_dataset_audio/training/config.py
@src/small_dataset_audio/training/metrics.py
@src/small_dataset_audio/training/runner.py
@src/small_dataset_audio/data/dataset.py
@src/small_dataset_audio/audio/io.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement the train command with Rich progress and SIGINT handling</name>
  <files>
    src/small_dataset_audio/cli/train.py
    src/small_dataset_audio/cli/__init__.py
  </files>
  <action>
Create `src/small_dataset_audio/cli/train.py`:

1. Create Typer sub-app: `app = typer.Typer()`.

2. Create `@app.command()` function `train()` (note: name it `train_cmd` or similar to avoid shadowing the training.loop.train import) with these parameters:
   - `dataset_dir: Path = typer.Argument(..., help="Path to audio dataset directory", exists=True, file_okay=False, dir_okay=True, resolve_path=True)`
   - `preset: str = typer.Option("auto", "--preset", help="Training preset: auto, conservative, balanced, aggressive")`
   - `epochs: Annotated[Optional[int], typer.Option("--epochs", "-e", help="Override max epochs")] = None`
   - `learning_rate: Annotated[Optional[float], typer.Option("--lr", help="Override learning rate")] = None`
   - `batch_size: Annotated[Optional[int], typer.Option("--batch-size", help="Override batch size")] = None`
   - `output_dir: Annotated[Optional[Path], typer.Option("--output-dir", "-o", help="Training output directory")] = None`
   - `device: str = typer.Option("auto", "--device", help="Compute device: auto, mps, cuda, cpu")`
   - `config: Annotated[Optional[Path], typer.Option("--config", help="Config file path")] = None`
   - `json_output: bool = typer.Option(False, "--json", help="Output results as JSON")`

3. Command body (ALL imports lazy inside function body):
   - `console = Console(stderr=True)` for all Rich output.
   - Call `bootstrap(config, device)` to get `(app_config, torch_device, config_path)`.
   - Resolve output_dir: if None, create a timestamped subdirectory under config's training output path (e.g., `resolve_path(app_config["paths"].get("models", "data/models"), base_dir=config_path.parent) / f"train_{datetime.now().strftime('%Y%m%d_%H%M%S')}"` -- or use a training-specific output path if one exists in config). Check what `train()` expects for output_dir and match that pattern.
   - Collect audio files from dataset_dir using `collect_audio_files(dataset_dir)` from `audio.io` or `data.dataset`. Validate the dataset directory exists and has audio files. If empty, print error and `raise typer.Exit(code=1)`.
   - Print dataset summary to stderr: file count, directory path.

4. Build TrainingConfig:
   - Import `get_adaptive_config` from `training.config` and `OverfittingPreset`.
   - If `preset == "auto"`: call `get_adaptive_config(len(file_paths))` to get a TrainingConfig sized to the dataset.
   - If `preset` is one of "conservative", "balanced", "aggressive": call `get_adaptive_config(len(file_paths))` then override `training_config.preset = OverfittingPreset(preset)` and apply the preset's params. Or check if `get_adaptive_config` accepts a preset parameter -- if not, create config manually using the preset.
   - Apply individual overrides: if `epochs` is not None, set `training_config.max_epochs = epochs`. Same for `learning_rate` -> `training_config.learning_rate` and `batch_size` -> `training_config.batch_size`.
   - Print training config summary to stderr (epochs, LR, batch size, preset name).

5. Set up SIGINT handling:
   ```python
   import signal
   import threading
   cancel_event = threading.Event()

   def handle_sigint(signum, frame):
       console.print("\n[yellow]Cancelling training (saving checkpoint)...[/yellow]")
       cancel_event.set()

   original_handler = signal.getsignal(signal.SIGINT)
   signal.signal(signal.SIGINT, handle_sigint)
   ```

6. Create Rich Progress with custom columns (per research pattern):
   ```python
   from rich.progress import Progress, TextColumn, BarColumn, TimeRemainingColumn, SpinnerColumn

   with Progress(
       SpinnerColumn(),
       TextColumn("[bold blue]Epoch {task.fields[epoch]}/{task.fields[total_epochs]}"),
       BarColumn(),
       TextColumn("train={task.fields[train_loss]:.4f}"),
       TextColumn("val={task.fields[val_loss]:.4f}"),
       TimeRemainingColumn(),
       console=console,  # stderr
   ) as progress:
       task_id = progress.add_task(
           "Training",
           total=training_config.max_epochs,
           epoch=0,
           total_epochs=training_config.max_epochs,
           train_loss=0.0,
           val_loss=0.0,
       )
   ```

7. Define CLI callback for training events:
   ```python
   def cli_callback(event):
       from small_dataset_audio.training.metrics import (
           EpochMetrics, TrainingCompleteEvent, PreviewEvent
       )
       if isinstance(event, EpochMetrics):
           progress.update(
               task_id,
               completed=event.epoch + 1,
               epoch=event.epoch + 1,
               total_epochs=event.total_epochs,
               train_loss=event.train_loss,
               val_loss=event.val_loss,
           )
       elif isinstance(event, TrainingCompleteEvent):
           pass  # Handled after train() returns
       elif isinstance(event, PreviewEvent):
           console.print(f"  [dim]Preview saved: {event.path}[/dim]")
   ```

8. Call `train()` directly (NOT TrainingRunner -- locked anti-pattern from research):
   ```python
   from small_dataset_audio.training.loop import train as run_training
   result = run_training(
       config=training_config,
       file_paths=file_paths,
       output_dir=output_dir,
       device=torch_device,
       callback=cli_callback,
       cancel_event=cancel_event,
   )
   ```

9. After training completes:
   - Restore original signal handler: `signal.signal(signal.SIGINT, original_handler)`.
   - If `cancel_event.is_set()`: print cancellation message, exit with code 3.
   - Otherwise: print completion summary (epochs completed, final train/val loss, output directory, best checkpoint path).
   - If `json_output`: print `json.dumps(result_summary, indent=2)` to stdout.
   - Otherwise: print human-readable summary to stderr, print output_dir path to stdout.

10. Update `cli/__init__.py` to register train sub-typer:
    `from small_dataset_audio.cli.train import app as train_app`
    `app.add_typer(train_app, name="train", help="Train models on audio datasets")`

IMPORTANT: Call `train()` directly, NOT `TrainingRunner` (pitfall #3 from research). The background thread pattern is for the GUI. The training loop already accepts `callback` and `cancel_event` parameters directly.

IMPORTANT: Progress bar uses `console = Console(stderr=True)` to keep stdout clean for piping.

IMPORTANT: Exit code 3 on cancellation (per research exit code table). Exit code 1 on errors. Exit code 0 on success.

IMPORTANT: Training progress must use progress bars, not log lines (locked decision from user).
  </action>
  <verify>
Run `uv run sda train --help` -- should show all options (dataset_dir, preset, epochs, lr, batch-size, output-dir, device, config, json).
Run `uv run python -c "from small_dataset_audio.cli.train import app; print('OK')"` -- should succeed without heavy imports.
  </verify>
  <done>
`sda train DATASET_DIR` trains a model showing Rich progress bar with epoch/loss/ETA. `sda train DIR --preset conservative --epochs 50` uses conservative preset with 50-epoch override. Ctrl+C saves checkpoint and exits with code 3. `--json` outputs training results as JSON. Training output directory printed to stdout on completion.
  </done>
</task>

<task type="auto">
  <name>Task 2: Verify full CLI integration and bare sda backward compatibility</name>
  <files>
    src/small_dataset_audio/cli/__init__.py
  </files>
  <action>
1. Ensure all four subcommand groups are registered in `cli/__init__.py`:
   - `generate` from cli.generate
   - `train` from cli.train
   - `model` from cli.model
   - `ui` from cli.ui (or defined inline)

2. Verify the import chain works by running:
   - `uv run sda --help` (shows all subcommands)
   - `uv run sda generate --help`
   - `uv run sda train --help`
   - `uv run sda model --help`
   - `uv run sda model list --help`
   - `uv run sda model info --help`
   - `uv run sda model delete --help`
   - `uv run sda ui --help`

3. Test that `sda --help` completes in under 1 second (no heavy imports at parse time):
   - Run `time uv run sda --help` and confirm.

4. Verify `uv run python -m small_dataset_audio --help` matches `sda --help`.

5. If any registration issues exist (import errors, wrong command names), fix them in `cli/__init__.py`.

6. Ensure exit codes are consistent:
   - 0 for success
   - 1 for general errors (typer.Exit(code=1))
   - 2 for not-found errors (model not found)
   - 3 for training cancelled

7. Make sure the default callback (bare `sda` with no subcommand) still works correctly -- it should trigger the GUI launch flow.
  </action>
  <verify>
Run `uv run sda --help` -- lists generate, train, model, ui. Completes in under 1 second.
Run `uv run sda generate --help` -- shows generate options.
Run `uv run sda train --help` -- shows train options.
Run `uv run sda model list --help` -- shows list options.
Run `uv run python -m small_dataset_audio --help` -- matches sda --help.
  </verify>
  <done>
All CLI subcommands registered and accessible. `sda --help` shows complete command tree. `python -m small_dataset_audio` works identically. Help output completes in under 1 second. Bare `sda` triggers GUI launch. All four command groups (generate, train, model, ui) functional.
  </done>
</task>

</tasks>

<verification>
1. `uv run sda --help` shows all 4 subcommand groups, completes in <1s
2. `uv run sda train --help` shows all training options
3. `uv run sda generate --help` shows all generation options
4. `uv run sda model list --help`, `sda model info --help`, `sda model delete --help` all work
5. `uv run python -m small_dataset_audio --help` matches `sda --help`
6. All cli modules importable: `python -c "from small_dataset_audio.cli import app; print('OK')"`
7. No torch imports at module level (verified by fast --help response)
</verification>

<success_criteria>
- `sda train DATASET_DIR` shows Rich progress bar with epoch/loss/ETA columns
- Ctrl+C during training saves checkpoint and exits with code 3
- `sda train DIR --preset conservative` uses conservative training preset
- `sda train DIR --epochs 50 --lr 0.001` overrides individual training params
- `sda train DIR --json` outputs training results as JSON to stdout
- All 4 subcommand groups registered and accessible from `sda --help`
- `sda` with no args launches GUI (backward compatible)
- `python -m small_dataset_audio` works identically to `sda`
- CLI help response time under 1 second
</success_criteria>

<output>
After completion, create `.planning/phases/09-cli-interface/09-03-SUMMARY.md`
</output>
