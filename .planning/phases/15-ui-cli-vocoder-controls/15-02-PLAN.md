---
phase: 15-ui-cli-vocoder-controls
plan: 02
type: execute
wave: 2
depends_on: ["15-01"]
files_modified:
  - src/distill/cli/generate.py
autonomous: true
requirements: [CLI-01, CLI-03]
must_haves:
  truths:
    - "Running `distill generate model --vocoder bigvgan` selects BigVGAN vocoder"
    - "Running `distill generate model` (no flag) uses auto selection and prints vocoder info to stderr"
    - "Running `distill generate model --vocoder hifigan` on a model without per-model vocoder exits with non-zero status and clear error"
    - "BigVGAN first-time download shows Rich progress bar in terminal (not default tqdm)"
    - "JSON output includes vocoder field with name and selection"
  artifacts:
    - path: "src/distill/cli/generate.py"
      provides: "--vocoder flag, vocoder status line, Rich download progress, JSON vocoder field"
      contains: "--vocoder"
  key_links:
    - from: "src/distill/cli/generate.py"
      to: "src/distill/vocoder/__init__.py"
      via: "resolve_vocoder() call with tqdm_class=tqdm_rich"
      pattern: "resolve_vocoder"
    - from: "src/distill/cli/generate.py"
      to: "tqdm.rich"
      via: "tqdm_rich class passed as tqdm_class for Rich progress"
      pattern: "tqdm_rich"
---

<objective>
Add `--vocoder` CLI flag, Rich download progress, vocoder status line, and JSON vocoder field to the `distill generate` command. Users can select their vocoder from the CLI and see Rich-styled download progress on first use.

Purpose: Implements CLI-01 (--vocoder flag) and CLI-03 (Rich progress bar for downloads) -- the two CLI requirements for Phase 15.
Output: Updated `generate.py` with vocoder selection, status output, and Rich download progress.
</objective>

<execution_context>
@C:/Users/Taylor/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/Taylor/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/15-ui-cli-vocoder-controls/15-CONTEXT.md
@.planning/phases/15-ui-cli-vocoder-controls/15-RESEARCH.md
@.planning/phases/15-ui-cli-vocoder-controls/15-01-SUMMARY.md

<interfaces>
<!-- Key types from Plan 01 that this plan uses. -->

From src/distill/vocoder/__init__.py (created in Plan 01):
```python
def resolve_vocoder(
    selection: str,  # "auto", "bigvgan", "hifigan"
    loaded_model: "LoadedModel",
    device: str = "auto",
    tqdm_class: type | None = None,
) -> tuple["VocoderBase", dict]:
    """Returns (vocoder, info_dict).
    info_dict: {"name": str, "selection": str, "reason": str}
    Raises ValueError if hifigan requested but no per-model vocoder.
    """
```

From src/distill/cli/generate.py (existing):
```python
@app.callback(invoke_without_command=True)
def generate(
    ctx: typer.Context,
    model: str = typer.Argument(...),
    # ... many options ...
    json_output: bool = typer.Option(False, "--json"),
) -> None:

# Current vocoder creation (line 538-540):
from distill.vocoder import get_vocoder
vocoder = get_vocoder("bigvgan", device=str(torch_device))

# Current JSON output (line 577-581):
results.append({
    "file": str(export_path),
    "format": fmt_lower,
    "seed": result.seed_used,
})
```
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add --vocoder flag with resolve_vocoder, Rich progress, and JSON field</name>
  <files>src/distill/cli/generate.py</files>
  <action>
**Add `--vocoder` option to generate() function signature:**

```python
vocoder: str = typer.Option(
    "auto", "--vocoder",
    help="Vocoder selection: auto, bigvgan, hifigan",
),
```

Place it in the options list near `--device` and `--sample-rate` (the technical options section).

**Replace hardcoded vocoder creation with resolve_vocoder():**

In the single-model generation section (around line 538-542), replace:
```python
from distill.vocoder import get_vocoder
vocoder = get_vocoder("bigvgan", device=str(torch_device))
```

With:
```python
import warnings
from distill.vocoder import resolve_vocoder

# Suppress tqdm experimental warning for Rich integration
warnings.filterwarnings("ignore", message=".*experimental.*", category=Warning)

# Use Rich progress for CLI downloads (not for JSON output mode)
tqdm_cls = None
if not json_output:
    try:
        from tqdm.rich import tqdm_rich
        tqdm_cls = tqdm_rich
    except ImportError:
        pass  # Fall back to default tqdm if tqdm.rich unavailable

try:
    vocoder_instance, vocoder_info = resolve_vocoder(
        selection=vocoder,
        loaded_model=loaded,
        device=str(torch_device),
        tqdm_class=tqdm_cls,
    )
except ValueError as exc:
    raise typer.BadParameter(str(exc))
```

**Print vocoder status line to stderr on every generate call:**

After resolving vocoder, before generation loop:
```python
# Always print vocoder line to stderr (per CONTEXT.md locked decision)
vocoder_label = (
    "BigVGAN Universal" if vocoder_info["name"] == "bigvgan_universal"
    else "Per-model HiFi-GAN"
)
reason = vocoder_info.get("reason", "")
vocoder_line = f"[bold]Vocoder:[/bold] {vocoder_label} ({vocoder_info['selection']}"
if reason:
    vocoder_line += f" -- {reason}"
vocoder_line += ")"
console.print(vocoder_line)
```

**Update GenerationPipeline construction:**

Use `vocoder_instance` instead of the old `vocoder` variable:
```python
pipeline = GenerationPipeline(
    loaded.model, loaded.spectrogram, torch_device, vocoder=vocoder_instance
)
```

**Add vocoder field to JSON output:**

In both the blend mode results loop and the single-model results loop, add `"vocoder"` to each result dict:
```python
results.append({
    "file": str(export_path),
    "format": fmt_lower,
    "seed": result.seed_used,
    "vocoder": {
        "name": vocoder_info["name"],
        "selection": vocoder_info["selection"],
    },
})
```

**Handle blend mode vocoder resolution:**

In the blend mode section (around line 324), also resolve vocoder before blend generation. Use the same `resolve_vocoder()` approach but with the primary loaded model. The blend engine needs vocoder passed differently -- check how `BlendEngine.blend_generate()` handles vocoder. If the blend engine already has its own vocoder from Phase 14, ensure it uses the resolved one. Add the vocoder status line and JSON field in the blend path too.

**IMPORTANT per CONTEXT.md locked decisions:**
- `--vocoder` flag accepts: auto, bigvgan, hifigan
- Auto is the default -- no flag needed, `distill generate model` just works
- When `--vocoder hifigan` specified but no per-model vocoder: error and exit with `typer.BadParameter`
- Always print vocoder line to stderr: `Vocoder: BigVGAN Universal (auto -- no per-model vocoder)`
- Rich progress bar for downloads (not HuggingFace Hub's tqdm default)
- JSON output includes vocoder field: `{"vocoder": {"name": "bigvgan_universal", "selection": "auto"}}`
- Suppress `TqdmExperimentalWarning` from `tqdm.rich.tqdm_rich`
  </action>
  <verify>
    <automated>cd H:/dev/Distill-hifigan && python -c "from distill.cli.generate import generate; import inspect; sig = inspect.signature(generate); assert 'vocoder' in sig.parameters, 'Missing --vocoder param'; print('--vocoder flag present in generate() signature')"</automated>
  </verify>
  <done>
    - `--vocoder` flag exists on generate command accepting auto/bigvgan/hifigan
    - Auto is default (no flag needed)
    - Vocoder status line printed to stderr on every generate call with label + reason
    - Rich progress bar shown during BigVGAN download (tqdm_rich as tqdm_class)
    - JSON output includes `"vocoder": {"name": ..., "selection": ...}` field
    - `--vocoder hifigan` on model without per-model vocoder raises typer.BadParameter
    - TqdmExperimentalWarning suppressed
  </done>
</task>

</tasks>

<verification>
1. `python -c "from distill.cli.generate import generate; import inspect; sig = inspect.signature(generate); print('vocoder' in sig.parameters)"` -- returns True
2. `python -m distill generate --help` shows `--vocoder` option with auto/bigvgan/hifigan
3. Manual: `distill generate some_model --vocoder bigvgan` prints `Vocoder: BigVGAN Universal (bigvgan -- explicit)` to stderr
4. Manual: `distill generate some_model --json` output includes `"vocoder"` field in JSON
5. Manual: `distill generate some_model --vocoder hifigan` on model without per-model vocoder shows clean error, not traceback
</verification>

<success_criteria>
- `--vocoder` flag on generate command accepts auto, bigvgan, hifigan
- Auto is default behavior (no flag = auto)
- Vocoder status line always printed to stderr with label and reason
- BigVGAN download uses Rich progress bar (not default tqdm)
- JSON output includes vocoder field
- hifigan on incompatible model gives clean error exit
</success_criteria>

<output>
After completion, create `.planning/phases/15-ui-cli-vocoder-controls/15-02-SUMMARY.md`
</output>
