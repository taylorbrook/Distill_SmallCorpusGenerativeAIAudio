---
phase: 14-generation-pipeline-integration
plan: 02
type: execute
wave: 2
depends_on: ["14-01"]
files_modified:
  - src/distill/training/preview.py
  - src/distill/training/loop.py
  - src/distill/cli/generate.py
  - src/distill/ui/tabs/generate_tab.py
  - src/distill/ui/tabs/library_tab.py
  - src/distill/inference/blending.py
autonomous: true
requirements: [GEN-01, GEN-03]
must_haves:
  truths:
    - "Training previews (generate_preview and generate_reconstruction_preview) use the neural vocoder"
    - "CLI generate command defaults to 44100 sample rate"
    - "UI generate tab export sample rate dropdown defaults to 44100"
    - "All GenerationPipeline constructor call sites pass a vocoder instance"
    - "Export pipeline works unchanged -- vocoder output (numpy float32 arrays) flows through WAV/MP3/FLAC/OGG export identically"
  artifacts:
    - path: "src/distill/training/preview.py"
      provides: "Training preview functions with vocoder parameter"
      contains: "vocoder.mel_to_waveform"
    - path: "src/distill/cli/generate.py"
      provides: "CLI generate with 44100 default and vocoder pipeline"
      contains: "44100"
    - path: "src/distill/ui/tabs/generate_tab.py"
      provides: "UI generate tab with 44100 default"
      contains: '"44100"'
    - path: "src/distill/ui/tabs/library_tab.py"
      provides: "Library tab pipeline creation with vocoder"
      contains: "vocoder="
    - path: "src/distill/inference/blending.py"
      provides: "Blending pipeline creation with vocoder"
      contains: "vocoder="
  key_links:
    - from: "src/distill/training/loop.py"
      to: "src/distill/training/preview.py"
      via: "generate_preview called from training loop"
      pattern: "generate_preview"
    - from: "src/distill/ui/tabs/library_tab.py"
      to: "src/distill/inference/generation.py"
      via: "GenerationPipeline constructor with vocoder"
      pattern: "GenerationPipeline"
---

<objective>
Wire the vocoder through all remaining call sites: training previews, CLI, UI, and blending module. Update all default sample rates from 48000 to 44100.

Purpose: Completes the vocoder integration across the entire application. After this plan, every audio generation path -- generation, preview, blending, CLI, and UI -- uses the neural vocoder and defaults to 44.1kHz. The export pipeline (WAV/MP3/FLAC/OGG) works unchanged since it already accepts sample_rate as a parameter.

Output: All call sites updated, all defaults changed, training previews using vocoder.
</objective>

<execution_context>
@C:/Users/Taylor/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/Taylor/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/14-generation-pipeline-integration/14-RESEARCH.md
@.planning/phases/14-generation-pipeline-integration/14-01-SUMMARY.md
@src/distill/training/preview.py
@src/distill/training/loop.py
@src/distill/cli/generate.py
@src/distill/ui/tabs/generate_tab.py
@src/distill/ui/tabs/library_tab.py
@src/distill/inference/blending.py
@src/distill/inference/generation.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Wire vocoder into training previews and update sample rates</name>
  <files>src/distill/training/preview.py</files>
  <action>
1. Update `generate_preview()` signature:
   - Add `vocoder` parameter (required, no default) after `sample_rate`
   - Change `sample_rate` default from `48_000` to `44_100`
   - Add vocoder parameter docstring: "vocoder : VocoderBase  Neural vocoder for mel-to-waveform conversion. Required -- Griffin-Lim is removed."

2. Update `generate_preview()` body:
   - Replace `waveforms = spectrogram.mel_to_waveform(mel_recon.cpu())` with:
     ```python
     from distill.inference.generation import _vocoder_with_fallback
     waveforms = _vocoder_with_fallback(vocoder, mel_recon, vocoder._device)
     waveforms = waveforms.cpu()
     ```
   - There is NO Griffin-Lim fallback. If vocoder is not provided, the call will fail at the caller level (TypeError for missing argument). This is intentional per user decision: "Griffin-Lim is removed entirely in Phase 14 -- no fallback, no hidden code, no legacy path."
   - Update the waveform indexing: after vocoder, shape is [B, 1, samples], so `audio = waveforms[i, 0]` works. The `.cpu()` call above ensures waveforms are on CPU before indexing.

3. Update `generate_reconstruction_preview()` signature:
   - Add `vocoder` parameter (required, no default) after `sample_rate`
   - Change `sample_rate` default from `48_000` to `44_100`

4. Update `generate_reconstruction_preview()` body:
   - Replace both `spectrogram.mel_to_waveform()` calls (for orig and recon) with vocoder calls:
     ```python
     from distill.inference.generation import _vocoder_with_fallback
     orig_waveforms = _vocoder_with_fallback(vocoder, sample_batch.cpu(), vocoder._device)
     recon_waveforms = _vocoder_with_fallback(vocoder, recon.cpu(), vocoder._device)
     orig_waveforms = orig_waveforms.cpu()
     recon_waveforms = recon_waveforms.cpu()
     ```
   - No Griffin-Lim fallback here either. Vocoder is required.

5. Update the module docstring at the top:
   - Replace "InverseMelScale + GriffinLim run on CPU" with "Neural vocoder (BigVGAN) used for all mel-to-waveform conversion"
   - Remove any references to Griffin-Lim as a fallback or legacy path
   - Update design notes accordingly
  </action>
  <verify>
Run: `python -c "from distill.training.preview import generate_preview, generate_reconstruction_preview; import inspect; sig_gp = inspect.signature(generate_preview); sig_rp = inspect.signature(generate_reconstruction_preview); assert 'vocoder' in sig_gp.parameters, 'generate_preview missing vocoder'; assert 'vocoder' in sig_rp.parameters, 'generate_reconstruction_preview missing vocoder'; assert sig_gp.parameters['sample_rate'].default == 44100, f'Expected 44100 default'; print('Training preview functions updated: PASS')"` -- should print PASS.

Verify no Griffin-Lim fallback: `python -c "import ast; source = open('src/distill/training/preview.py').read(); assert 'mel_to_waveform' not in source or 'spectrogram.mel_to_waveform' not in source, 'Griffin-Lim fallback still present'; print('No Griffin-Lim fallback: PASS')"` -- should print PASS.
  </verify>
  <done>Both training preview functions require vocoder parameter (not optional), default sample_rate is 44100, all mel-to-waveform conversion uses neural vocoder exclusively. No Griffin-Lim fallback exists.</done>
</task>

<task type="auto">
  <name>Task 2: Update all GenerationPipeline callers and sample rate defaults</name>
  <files>
    src/distill/cli/generate.py
    src/distill/ui/tabs/generate_tab.py
    src/distill/ui/tabs/library_tab.py
    src/distill/inference/blending.py
  </files>
  <action>
1. **src/distill/cli/generate.py:**
   - Change `sample_rate` default from `48000` to `44100` on line ~224: `sample_rate: int = typer.Option(44100, "--sample-rate", help="Output sample rate: 44100, 48000, 96000")`
   - Update the `GenerationPipeline(loaded.model, loaded.spectrogram, torch_device)` call (~line 538) to pass vocoder:
     ```python
     from distill.vocoder import get_vocoder
     vocoder = get_vocoder("bigvgan", device=str(torch_device))
     pipeline = GenerationPipeline(loaded.model, loaded.spectrogram, torch_device, vocoder=vocoder)
     ```
     The vocoder should be created ONCE before the generation loop, not inside it. Place the vocoder creation right before the pipeline creation.

2. **src/distill/ui/tabs/generate_tab.py:**
   - Change the Export Sample Rate dropdown default from `"48000"` to `"44100"` (~line 939)

3. **src/distill/ui/tabs/library_tab.py:**
   - Update the `GenerationPipeline(model=..., spectrogram=..., device=...)` call (~line 164) to pass vocoder:
     ```python
     from distill.vocoder import get_vocoder
     vocoder = get_vocoder("bigvgan", device=device_str)
     app_state.pipeline = GenerationPipeline(
         model=loaded.model,
         spectrogram=loaded.spectrogram,
         device=loaded.device,
         vocoder=vocoder,
     )
     ```
     Place the vocoder creation just before pipeline creation. Use lazy import (inside the function body) for get_vocoder.

4. **src/distill/inference/blending.py:**
   - There are 3 `GenerationPipeline(...)` calls (~lines 554, 675, 721). Each needs vocoder passed.
   - At the top of each function that creates a GenerationPipeline (or at a shared scope), create a vocoder once:
     ```python
     from distill.vocoder import get_vocoder
     vocoder = get_vocoder("bigvgan", device=str(slot.device))
     ```
   - Pass `vocoder=vocoder` to each GenerationPipeline constructor.
   - For the blending function that creates multiple pipelines from different slots, create the vocoder from the first slot's device (vocoder will be moved internally if needed, but typically all slots share the same device).

Note: All vocoder imports must be lazy (inside function bodies, not at module level) consistent with project pattern.
  </action>
  <verify>
Run: `python -c "from distill.inference.generation import GenerationConfig; gc = GenerationConfig(); assert gc.sample_rate == 44100; print(f'GenerationConfig default: {gc.sample_rate}'); print('PASS')"` -- confirm generation default.

Run: `python -c "import ast, sys; tree = ast.parse(open('src/distill/cli/generate.py').read()); print('CLI parses OK')"` -- confirm CLI syntax valid.

Run: `python -c "import ast; tree = ast.parse(open('src/distill/ui/tabs/generate_tab.py').read()); print('UI generate_tab parses OK')"` -- confirm UI syntax valid.

Run: `python -c "import ast; tree = ast.parse(open('src/distill/ui/tabs/library_tab.py').read()); print('library_tab parses OK')"` -- confirm library_tab syntax valid.

Run: `python -c "import ast; tree = ast.parse(open('src/distill/inference/blending.py').read()); print('blending parses OK')"` -- confirm blending syntax valid.
  </verify>
  <done>CLI defaults to 44100 sample rate, UI generate tab defaults to "44100", all GenerationPipeline constructor call sites pass vocoder, blending module passes vocoder to all pipeline instances.</done>
</task>

<task type="auto">
  <name>Task 3: Wire vocoder into training loop for preview generation</name>
  <files>src/distill/training/loop.py</files>
  <action>
1. In the `train()` function, locate the lazy imports block near line ~330-345. Add a new lazy import:
   ```python
   from distill.vocoder import get_vocoder
   ```

2. In the Setup section (after `spectrogram.to(device)` around line ~367), create the vocoder instance once:
   ```python
   # Create vocoder for preview generation
   vocoder = get_vocoder("bigvgan", device=str(device))
   ```
   Place this AFTER the spectrogram setup but BEFORE the model initialization (or right after -- the vocoder is independent of the model). The vocoder is created once and reused for all preview calls throughout training.

3. Locate the `generate_preview()` call (~line 587). Add `vocoder=vocoder` to the call:
   ```python
   preview_paths = generate_preview(
       model=model,
       spectrogram=spectrogram,
       output_dir=preview_dir,
       epoch=epoch,
       device=device,
       vocoder=vocoder,
   )
   ```

4. Update the `sample_rate` passed to PreviewEvent (~line 599). Change `sample_rate=spec_config.sample_rate` to `sample_rate=vocoder.sample_rate` since the preview audio is now at the vocoder's native rate (44100), not the spectrogram's rate (48000).

5. If `generate_reconstruction_preview` is called anywhere in loop.py, add `vocoder=vocoder` there too. (Current grep shows it is NOT called from loop.py, so this step may be a no-op -- but check to be safe.)

Note: The vocoder auto-downloads weights on first call if not cached. This happens once at training start, not per-preview. The `get_vocoder` factory handles auto-download with progress per user decision ("If BigVGAN weights aren't downloaded: auto-download with progress, then generate -- no blocking error").
  </action>
  <verify>
Run: `python -c "import ast; tree = ast.parse(open('src/distill/training/loop.py').read()); print('loop.py parses OK')"` -- confirm syntax valid.

Run: `python -c "source = open('src/distill/training/loop.py').read(); assert 'vocoder=vocoder' in source, 'vocoder not passed to generate_preview'; assert 'get_vocoder' in source, 'get_vocoder not imported'; print('loop.py vocoder wiring: PASS')"` -- confirm vocoder is wired.
  </verify>
  <done>Training loop creates BigVGAN vocoder once at setup and passes it to generate_preview. Preview audio uses vocoder's native sample rate. No Griffin-Lim path remains in the training preview pipeline.</done>
</task>

</tasks>

<verification>
1. `python -c "from distill.cli.generate import generate; print('CLI generate imports OK')"` -- CLI module loads
2. `python -c "from distill.ui.tabs.generate_tab import create_generate_tab; print('UI generate_tab imports OK')"` -- UI tab loads
3. `python -c "from distill.inference.blending import generate_blend, generate_multi_blend; print('blending imports OK')"` -- blending loads
4. `python -c "from distill.training.preview import generate_preview; import inspect; sig = inspect.signature(generate_preview); assert sig.parameters['sample_rate'].default == 44100; print('preview default 44100: PASS')"` -- training preview defaults
5. `python -c "import ast; tree = ast.parse(open('src/distill/training/loop.py').read()); print('loop.py parses OK')"` -- loop.py syntax valid
6. `python -c "source = open('src/distill/training/loop.py').read(); assert 'vocoder=vocoder' in source; assert 'get_vocoder' in source; print('loop.py vocoder wiring: PASS')"` -- vocoder wired in training loop
7. Grep all files for remaining `spectrogram.mel_to_waveform` in generation/preview paths -- should only appear in vocoder/mel_adapter.py (internal) and controls/analyzer.py (analysis, not generation). Must NOT appear in preview.py.
</verification>

<success_criteria>
- Training preview functions require vocoder parameter (no Griffin-Lim fallback)
- Training loop creates vocoder once and passes it to generate_preview
- CLI --sample-rate defaults to 44100
- UI export sample rate dropdown defaults to "44100"
- All 5 GenerationPipeline constructor call sites (CLI, library_tab, 3x blending) pass vocoder
- All files parse without syntax errors
- The only remaining spectrogram.mel_to_waveform calls are in vocoder/mel_adapter.py and controls/analyzer.py (both non-generation paths)
- No Griffin-Lim code path remains in any generation or preview path
</success_criteria>

<output>
After completion, create `.planning/phases/14-generation-pipeline-integration/14-02-SUMMARY.md`
</output>
