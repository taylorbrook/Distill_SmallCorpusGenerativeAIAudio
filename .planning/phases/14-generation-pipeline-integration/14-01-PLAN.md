---
phase: 14-generation-pipeline-integration
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/distill/inference/generation.py
  - src/distill/inference/chunking.py
autonomous: true
requirements: [GEN-01, GEN-02]
must_haves:
  truths:
    - "GenerationPipeline accepts a vocoder parameter and uses it for all mel-to-waveform conversion"
    - "All three chunking functions (crossfade, latent_interp, slider) call vocoder.mel_to_waveform instead of spectrogram.mel_to_waveform"
    - "Internal sample rate is vocoder.sample_rate (44100) for all downstream processing (anti-alias, spatial, normalize)"
    - "Resampler uses Kaiser-windowed sinc interpolation with lowpass_filter_width=64"
    - "GPU OOM during vocoder inference falls back to CPU with a warning"
  artifacts:
    - path: "src/distill/inference/generation.py"
      provides: "GenerationPipeline with vocoder injection, Kaiser resampler, OOM fallback"
      contains: "self.vocoder"
    - path: "src/distill/inference/chunking.py"
      provides: "Chunking functions with vocoder parameter replacing spectrogram.mel_to_waveform"
      contains: "vocoder.mel_to_waveform"
  key_links:
    - from: "src/distill/inference/generation.py"
      to: "src/distill/vocoder/__init__.py"
      via: "get_vocoder factory in GenerationPipeline.__init__"
      pattern: "get_vocoder"
    - from: "src/distill/inference/generation.py"
      to: "src/distill/inference/chunking.py"
      via: "vocoder passed through to chunking functions"
      pattern: "vocoder=self\\.vocoder"
---

<objective>
Wire the BigVGAN neural vocoder through the core generation pipeline and all three chunking code paths, replacing Griffin-Lim mel-to-waveform calls.

Purpose: This is the foundational rewiring that makes every generation path produce audio through the neural vocoder instead of Griffin-Lim. The internal sample rate transitions from 48kHz to 44.1kHz (BigVGAN native), and resampling upgrades to Kaiser-windowed sinc interpolation.

Output: Updated GenerationPipeline with vocoder injection, updated chunking functions, OOM fallback helper, and high-quality Kaiser resampler.
</objective>

<execution_context>
@C:/Users/Taylor/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/Taylor/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/14-generation-pipeline-integration/14-RESEARCH.md
@src/distill/inference/generation.py
@src/distill/inference/chunking.py
@src/distill/vocoder/__init__.py
@src/distill/vocoder/bigvgan_vocoder.py
@src/distill/vocoder/base.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Inject vocoder into GenerationPipeline and update internal sample rate</name>
  <files>src/distill/inference/generation.py</files>
  <action>
1. Add `vocoder` parameter to `GenerationPipeline.__init__()`:
   ```python
   def __init__(self, model, spectrogram, device, vocoder=None):
       ...
       self.vocoder = vocoder or get_vocoder("bigvgan", device=str(device))
   ```
   Add lazy import for `get_vocoder` from `distill.vocoder` inside `__init__` (project pattern: lazy imports).

2. Add a module-level `_vocoder_with_fallback(vocoder, mel, original_device)` helper function for GPU OOM fallback:
   - Try `vocoder.mel_to_waveform(mel)`
   - On RuntimeError with "out of memory" in the message: log warning, `torch.cuda.empty_cache()` if CUDA available, move vocoder to CPU, run inference on `mel.cpu()`, move vocoder back to original_device in a `finally` block, return result
   - Re-raise any other RuntimeError

3. In `GenerationPipeline.generate()`:
   - Change `internal_sr = 48_000` to `internal_sr = self.vocoder.sample_rate` (will be 44100 for BigVGAN)
   - `chunk_samples` computation stays the same: `int(config.chunk_duration_s * self.spectrogram.config.sample_rate)` -- this is correct because chunk_samples feeds into spectrogram.get_mel_shape() which uses the spectrogram's 48kHz config for mel frame count computation. The vocoder then produces audio at its native rate from those mel frames.

4. Update all chunk generation calls in `generate()` to pass `vocoder=self.vocoder`:
   - `_generate_chunks_from_vector(..., vocoder=self.vocoder)`
   - `generate_chunks_crossfade(..., vocoder=self.vocoder)`
   - `generate_chunks_latent_interp(..., vocoder=self.vocoder)`
   Also update `_generate_right_channel()` to pass `vocoder=self.vocoder` to all three call sites.

5. Update `_generate_chunks_from_vector()` function signature to accept `vocoder=None` parameter. Replace the line `wav = spectrogram.mel_to_waveform(combined_mel)` with `wav = _vocoder_with_fallback(vocoder, combined_mel, vocoder._device)`. Update the return to handle the vocoder output shape: `wav.squeeze().cpu().numpy().astype(np.float32)` (add `.cpu()` since vocoder output may be on GPU).

6. Upgrade `_get_resampler()` to use Kaiser-windowed sinc interpolation per user decision:
   ```python
   _resampler_cache[key] = torchaudio.transforms.Resample(
       orig_freq,
       new_freq,
       resampling_method="sinc_interp_kaiser",
       lowpass_filter_width=64,
   )
   ```

7. Change `GenerationConfig.sample_rate` default from `48_000` to `44_100` per user decision ("Default export sample rate is 44.1kHz (BigVGAN native)").

8. Update module docstring: replace "All internal audio processing at 48 kHz" with "All internal audio processing at vocoder native rate (44.1 kHz for BigVGAN)" and "Resampler instances cached" with "Kaiser-windowed sinc resampler instances cached".

9. Update `GenerationPipeline` class docstring to mention the vocoder parameter.

10. Update `generate()` method docstring step 7: "Resample to target sample rate (if different from vocoder native rate)".
  </action>
  <verify>
Run: `python -c "from distill.inference.generation import GenerationPipeline, GenerationConfig, _get_resampler, _vocoder_with_fallback; print('imports OK'); gc = GenerationConfig(); print(f'default sample_rate: {gc.sample_rate}'); assert gc.sample_rate == 44100, f'Expected 44100, got {gc.sample_rate}'; print('PASS')"` -- should print "imports OK", "default sample_rate: 44100", "PASS".
  </verify>
  <done>GenerationPipeline accepts vocoder parameter with auto-creation fallback, internal_sr uses vocoder.sample_rate, _get_resampler uses Kaiser window, GenerationConfig defaults to 44100, OOM fallback helper exists, all chunk generation calls pass vocoder.</done>
</task>

<task type="auto">
  <name>Task 2: Update chunking functions to use vocoder instead of spectrogram.mel_to_waveform</name>
  <files>src/distill/inference/chunking.py</files>
  <action>
1. Update `generate_chunks_crossfade()` signature to add `vocoder=None` parameter after `overlap_samples`. Replace the line `wav = spectrogram.mel_to_waveform(combined_mel)` with:
   ```python
   from distill.inference.generation import _vocoder_with_fallback
   wav = _vocoder_with_fallback(vocoder, combined_mel, vocoder._device)
   return wav.squeeze().cpu().numpy().astype(np.float32)
   ```
   (Add `.cpu()` before `.numpy()` since vocoder output may be on GPU.)

2. Update `generate_chunks_latent_interp()` signature to add `vocoder=None` parameter after `steps_between`. Apply the same replacement as step 1.

3. Update the module docstring at the top of chunking.py:
   - Replace "before a single Griffin-Lim pass" with "before a single vocoder pass"
   - Replace reference to `spectrogram.mel_to_waveform()` with "vocoder.mel_to_waveform()"
   - Remove the note about "spectrogram.mel_to_waveform() forces CPU"
   - Update the `synthesize_continuous_mel` docstring: change "A single Griffin-Lim pass on this mel reconstructs phase" to "A single vocoder pass on this mel produces the final waveform"

4. Update parameter docstrings for both functions: change `spectrogram : AudioSpectrogram` doc to note it's used for mel shape computation, not mel-to-waveform. Add `vocoder : VocoderBase` parameter doc.

Note: Do NOT import _vocoder_with_fallback at module level. Import it lazily inside the function bodies (consistent with project pattern of lazy imports).
  </action>
  <verify>
Run: `python -c "from distill.inference.chunking import generate_chunks_crossfade, generate_chunks_latent_interp; import inspect; sig_cf = inspect.signature(generate_chunks_crossfade); sig_li = inspect.signature(generate_chunks_latent_interp); assert 'vocoder' in sig_cf.parameters, 'crossfade missing vocoder'; assert 'vocoder' in sig_li.parameters, 'latent_interp missing vocoder'; print('Both functions accept vocoder parameter: PASS')"` -- should print PASS.
  </verify>
  <done>Both generate_chunks_crossfade and generate_chunks_latent_interp accept vocoder parameter and use it for mel-to-waveform conversion. Docstrings updated to reflect vocoder usage instead of Griffin-Lim.</done>
</task>

</tasks>

<verification>
1. `python -c "from distill.inference.generation import GenerationPipeline, GenerationConfig; gc = GenerationConfig(); assert gc.sample_rate == 44100"` -- default sample rate is 44100
2. `python -c "from distill.inference.generation import _get_resampler; r = _get_resampler(44100, 48000); print(type(r)); print('Kaiser resampler created')"` -- resampler creates without error
3. `python -c "from distill.inference.generation import _vocoder_with_fallback; print('OOM fallback function exists')"` -- OOM fallback exists
4. `python -c "import inspect; from distill.inference.chunking import generate_chunks_crossfade, generate_chunks_latent_interp; from distill.inference.generation import _generate_chunks_from_vector; assert 'vocoder' in inspect.signature(generate_chunks_crossfade).parameters; assert 'vocoder' in inspect.signature(generate_chunks_latent_interp).parameters; assert 'vocoder' in inspect.signature(_generate_chunks_from_vector).parameters; print('All 3 functions have vocoder param')"` -- all functions accept vocoder
</verification>

<success_criteria>
- GenerationPipeline constructor accepts optional vocoder, auto-creates BigVGAN if not provided
- Internal sample rate derived from vocoder.sample_rate (44100 for BigVGAN)
- All three chunking functions use vocoder.mel_to_waveform instead of spectrogram.mel_to_waveform
- GenerationConfig.sample_rate defaults to 44100
- _get_resampler uses Kaiser-windowed sinc with lowpass_filter_width=64
- _vocoder_with_fallback handles GPU OOM with CPU fallback
</success_criteria>

<output>
After completion, create `.planning/phases/14-generation-pipeline-integration/14-01-SUMMARY.md`
</output>
