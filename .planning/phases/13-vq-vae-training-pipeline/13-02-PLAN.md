---
phase: 13-vq-vae-training-pipeline
plan: 02
type: execute
wave: 2
depends_on:
  - 13-01
files_modified:
  - src/distill/ui/tabs/train_tab.py
  - src/distill/ui/components/loss_chart.py
  - src/distill/ui/state.py
autonomous: true
requirements:
  - UI-03

must_haves:
  truths:
    - "User can start VQ-VAE training from the training tab with RVQ levels slider and commitment weight input"
    - "Codebook size is auto-determined and displayed as read-only (no manual override in UI)"
    - "Per-level codebook health (utilization, perplexity, dead codes) is displayed during training in the stats panel"
    - "Loss chart shows commitment loss alongside train/val loss curves"
    - "Low utilization warnings are visible in the training stats panel when triggered"
  artifacts:
    - path: "src/distill/ui/tabs/train_tab.py"
      provides: "VQ-VAE training controls and codebook health display"
      contains: "rvq_levels"
    - path: "src/distill/ui/components/loss_chart.py"
      provides: "Extended loss chart with commitment loss line"
      contains: "commit"
  key_links:
    - from: "src/distill/ui/tabs/train_tab.py"
      to: "src/distill/training/runner.py"
      via: "TrainingRunner.start_vqvae() call"
      pattern: "start_vqvae\\("
    - from: "src/distill/ui/tabs/train_tab.py"
      to: "src/distill/training/metrics.py"
      via: "VQEpochMetrics consumption in _poll_training"
      pattern: "VQEpochMetrics"
    - from: "src/distill/ui/tabs/train_tab.py"
      to: "src/distill/training/config.py"
      via: "get_adaptive_vqvae_config for auto codebook sizing"
      pattern: "get_adaptive_vqvae_config"
---

<objective>
Update the Gradio training tab for VQ-VAE: replace v1.0-specific controls with VQ-VAE controls, display per-level codebook health during training, and extend the loss chart with commitment loss.

Purpose: Users need VQ-VAE-specific training controls and codebook health visibility (the key differentiator from v1.0 training) to effectively train and monitor VQ-VAE models.

Output: Updated training tab with VQ-VAE controls, real-time codebook health display, and enriched loss chart.
</objective>

<execution_context>
@C:/Users/Taylor/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/Taylor/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/13-vq-vae-training-pipeline/13-CONTEXT.md
@.planning/phases/13-vq-vae-training-pipeline/13-RESEARCH.md
@.planning/phases/13-vq-vae-training-pipeline/13-01-SUMMARY.md

@src/distill/ui/tabs/train_tab.py
@src/distill/ui/components/loss_chart.py
@src/distill/ui/state.py
@src/distill/training/metrics.py
@src/distill/training/runner.py
@src/distill/training/config.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Replace v1.0 training controls with VQ-VAE controls in train tab</name>
  <files>
    src/distill/ui/tabs/train_tab.py
    src/distill/ui/state.py
  </files>
  <action>
**train_tab.py** -- Transform the training tab from v1.0 VAE to VQ-VAE:

1. **Replace imports**: Add `VQEpochMetrics` and `VQStepMetrics` imports from `distill.training.metrics`. Add `VQVAEConfig`, `get_adaptive_vqvae_config` from `distill.training.config`. Remove the `_PRESET_MAP` and `_PRESET_DEFAULTS` dicts (v1.0 presets with KL weight are irrelevant for VQ-VAE).

2. **Replace config controls** in `build_train_tab()`:
   - Remove `preset_dd` dropdown (presets were v1.0-specific with KL annealing params).
   - Remove `kl_weight_slider` from advanced settings.
   - Keep `model_name_input`, `max_epochs_num`, `learning_rate_num` as-is.
   - Add `rvq_levels_slider`: `gr.Slider(minimum=2, maximum=4, step=1, value=3, label="RVQ Levels", info="Fewer levels = faster, more levels = finer detail")`.
   - Add `commitment_weight_num`: `gr.Number(value=0.25, label="Commitment Weight", precision=4)` or `gr.Slider(minimum=0.01, maximum=1.0, step=0.01, value=0.25, label="Commitment Weight", info="Controls codebook learning rate. Most users leave this at 0.25.")`.
   - Add `codebook_size_display`: `gr.Textbox(label="Codebook Size (auto)", interactive=False, value="Auto-determined from dataset size")` -- read-only display, updated when training starts to show actual auto-determined size.
   - Keep `dropout_slider` and `weight_decay_slider` in the Advanced accordion (they apply to VQ-VAE too).

3. **Remove `_on_preset_change` handler** and its `.change()` binding.

4. **Update `_start_training()`**:
   - Change signature to accept new UI inputs: `model_name, max_epochs, learning_rate, dropout, weight_decay, rvq_levels, commitment_weight`.
   - Build `VQVAEConfig` via `get_adaptive_vqvae_config(file_count)` for auto-sizing, then override: `config.max_epochs = int(max_epochs)`, `config.learning_rate = float(learning_rate)`, `config.dropout = float(dropout)`, `config.weight_decay = float(weight_decay)`, `config.num_quantizers = int(rvq_levels)`, `config.commitment_weight = float(commitment_weight)`.
   - Call `runner.start_vqvae(config=config, ...)` instead of `runner.start(config=config, ...)`.
   - The rest of the start logic (runner creation, metrics buffer reset, error handling) stays the same.

5. **Update `_resume_training()`**: Same pattern as `_start_training()` -- use VQVAEConfig and `runner.start_vqvae()`. (Note: resume from VQ-VAE checkpoint will need the runner to support it. For now, implement basic start; resume can be deferred since the runner's `resume()` method needs a VQ-VAE variant too. If time allows, add `runner.resume_vqvae()` -- otherwise mark resume_btn as hidden for now since VQ-VAE checkpoint resume is a v1.0 feature that needs adaptation.)

6. **Update `_training_callback()`**: Handle both v1.0 and VQ event types. Add: `if isinstance(event, VQEpochMetrics): app_state.metrics_buffer["epoch_metrics"].append(event)`. This works because the buffer just stores objects and the poll function reads them.

7. **Update `_poll_training()`**:
   - Detect whether epoch metrics are VQ-VAE type: check `if epoch_metrics and isinstance(epoch_metrics[-1], VQEpochMetrics)`.
   - For VQ-VAE metrics: Build stats string including codebook health:
     ```
     **Epoch {e}/{total}** | Train: {t:.4f} | Val: {v:.4f} | Recon: {r:.4f} | Commit: {c:.4f} | LR: {lr:.2e} | ETA: {eta}

     **Codebook Health:**
     | Level | Utilization | Perplexity | Dead Codes |
     |-------|-------------|------------|------------|
     | 0     | 85%         | 54.2       | 38         |
     | 1     | 72%         | 41.8       | 71         |
     ```
   - If `utilization_warnings` is not None and not empty, append a warning section:
     ```
     **Warnings:** Level 1: utilization 28% (below 30% threshold)
     ```
   - For v1.0 metrics (EpochMetrics instances): Keep existing stats format.

8. **Update start_btn.click() inputs/outputs** to match new control references.

**state.py** -- No structural changes needed. The `metrics_buffer` dict pattern (`{"epoch_metrics": [], "previews": [], "complete": False}`) works for both v1.0 and VQ-VAE events since it stores arbitrary objects.
  </action>
  <verify>
Launch the app with `python -m distill.ui` (or however the Gradio app starts) and verify the training tab renders without errors. Check that RVQ Levels slider appears with values 2-4, Commitment Weight input shows 0.25, Codebook Size shows "Auto-determined", and the KL Weight slider is gone.
  </verify>
  <done>
Training tab shows VQ-VAE controls (RVQ Levels, Commitment Weight, auto Codebook Size display). KL Weight and preset dropdown are removed. Start training calls the VQ-VAE training path. Poll function displays per-level codebook health table in stats panel. Low utilization warnings are visible when triggered.
  </done>
</task>

<task type="auto">
  <name>Task 2: Extend loss chart to include commitment loss and handle VQ metrics</name>
  <files>
    src/distill/ui/components/loss_chart.py
  </files>
  <action>
**loss_chart.py** -- Extend `build_loss_chart()` to handle both v1.0 and VQ-VAE epoch metrics:

1. Add detection: Check if the first metric in the list is a `VQEpochMetrics` instance (import from `distill.training.metrics`). Use `hasattr(epoch_metrics[0], 'val_commit_loss')` for a safe duck-type check (avoids circular import risk).

2. **For VQ-VAE metrics** (has `val_commit_loss`):
   - Plot 3 lines: Train Loss, Val Loss, Commitment Loss.
   - Extract: `train_losses = [m.train_loss ...]`, `val_losses = [m.val_loss ...]`, `commit_losses = [m.val_commit_loss ...]`.
   - Use a secondary y-axis or same axis (commitment loss is typically much smaller than reconstruction loss, so same axis with legend is fine -- use different line styles).
   - Colors: Train = blue, Val = orange, Commitment = green (dashed).
   - Title: "VQ-VAE Training Progress".

3. **For v1.0 metrics** (no `val_commit_loss`): Keep existing behavior exactly (Train Loss + Val Loss, title "Training Progress").

4. Close figures properly with `plt.close(fig)` after returning to prevent matplotlib memory leaks during long training runs. Actually, since the figure is returned to gr.Plot which handles display, do NOT close it -- just return it. But do ensure previous figures are closed by the caller or use `plt.close('all')` before creating new figure.
  </action>
  <verify>
Run `python -c "from distill.ui.components.loss_chart import build_loss_chart; print('chart OK')"`. Verify no import errors. The function signature hasn't changed, so existing callers still work.
  </verify>
  <done>
Loss chart renders commitment loss as a third line (green dashed) when given VQ-VAE epoch metrics. Title changes to "VQ-VAE Training Progress" for VQ metrics. v1.0 metrics still render with the original 2-line chart. No matplotlib memory leaks.
  </done>
</task>

</tasks>

<verification>
1. Training tab renders without errors: `python -c "from distill.ui.tabs.train_tab import build_train_tab; print('tab imports OK')"`
2. Loss chart handles both metric types: import and call with empty list returns None
3. VQ-VAE controls present: RVQ Levels (2-4), Commitment Weight (0.25 default), auto Codebook Size display
4. KL Weight slider removed from the UI
5. Poll function formats codebook health as markdown table
</verification>

<success_criteria>
- Training tab shows VQ-VAE-specific controls replacing v1.0 controls
- Codebook size is auto-determined and displayed read-only
- RVQ levels slider constrained to 2, 3, 4 with descriptive label
- Commitment weight pre-filled at 0.25
- Per-level codebook health displayed as inline table during training
- Loss chart shows commitment loss line for VQ-VAE training
- Low utilization warnings visible in stats panel
</success_criteria>

<output>
After completion, create `.planning/phases/13-vq-vae-training-pipeline/13-02-SUMMARY.md`
</output>
