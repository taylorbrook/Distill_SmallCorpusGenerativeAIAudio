---
phase: 02-data-pipeline-foundation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - pyproject.toml
  - src/small_dataset_audio/audio/__init__.py
  - src/small_dataset_audio/audio/io.py
  - src/small_dataset_audio/audio/validation.py
autonomous: true

must_haves:
  truths:
    - "Audio files (WAV, AIFF, MP3, FLAC) can be loaded as float32 tensors in [channels, samples] format"
    - "Audio metadata can be read without loading waveform data"
    - "Corrupt files are detected per-file without crashing the batch"
    - "Sample rate mismatches across a dataset are detected and reported"
    - "Datasets with fewer than min_file_count files are flagged"
    - "Files with unsupported formats are identified"
  artifacts:
    - path: "src/small_dataset_audio/audio/io.py"
      provides: "Audio I/O abstraction layer using soundfile"
      exports: ["AudioFile", "AudioMetadata", "load_audio", "get_metadata", "SUPPORTED_FORMATS"]
    - path: "src/small_dataset_audio/audio/validation.py"
      provides: "Dataset integrity validation"
      exports: ["validate_dataset", "check_file_integrity", "ValidationIssue", "Severity"]
    - path: "pyproject.toml"
      provides: "New dependencies: soundfile, numpy, matplotlib"
      contains: "soundfile"
  key_links:
    - from: "src/small_dataset_audio/audio/io.py"
      to: "soundfile"
      via: "sf.read() and sf.info() calls"
      pattern: "sf\\.read|sf\\.info"
    - from: "src/small_dataset_audio/audio/io.py"
      to: "torchaudio.transforms.Resample"
      via: "lazy import for resampling to target sample rate"
      pattern: "torchaudio\\.transforms"
    - from: "src/small_dataset_audio/audio/validation.py"
      to: "src/small_dataset_audio/audio/io.py"
      via: "imports get_metadata and check_file_integrity helpers"
      pattern: "from.*audio\\.io import|from.*audio import"
---

<objective>
Audio I/O abstraction layer and dataset validation -- the foundation all other data pipeline modules depend on.

Purpose: Every downstream module (augmentation, preprocessing, dataset, summary, thumbnails) needs to load audio and validate files. This plan creates the I/O abstraction using soundfile (avoiding torchaudio.load's TorchCodec/FFmpeg dependency) and the validation system that collects issues per-file without raising exceptions (matching Phase 1's validation pattern).

Output: `audio/io.py` with AudioFile/AudioMetadata dataclasses and load/metadata functions; `audio/validation.py` with dataset integrity checking; new dependencies (soundfile, numpy, matplotlib) added to pyproject.toml.
</objective>

<execution_context>
@/Users/taylorbrook/.claude/get-shit-done/workflows/execute-plan.md
@/Users/taylorbrook/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-data-pipeline-foundation/02-RESEARCH.md
@src/small_dataset_audio/audio/__init__.py
@src/small_dataset_audio/config/defaults.py
@src/small_dataset_audio/validation/environment.py
@pyproject.toml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add dependencies and implement audio I/O abstraction layer</name>
  <files>
    pyproject.toml
    src/small_dataset_audio/audio/io.py
  </files>
  <action>
1. Add new dependencies to pyproject.toml:
   - `"soundfile>=0.13.0"` -- audio file I/O (libsndfile bundled in pip wheel, no FFmpeg needed)
   - `"numpy>=1.26"` -- bridge soundfile numpy arrays to torch tensors
   - `"matplotlib>=3.9"` -- waveform thumbnail generation (used in Plan 03, but add now so uv.lock is updated once)
   Run `uv sync` to install and update uv.lock.

2. Create `src/small_dataset_audio/audio/io.py` with:

   **Constants:**
   - `SUPPORTED_FORMATS: set[str] = {"wav", "aiff", "mp3", "flac"}` (lowercase extensions)
   - `DEFAULT_SAMPLE_RATE: int = 48000` (project baseline from PROJECT.md)

   **Dataclasses:**
   - `AudioMetadata` dataclass with fields: `path: Path`, `sample_rate: int`, `num_channels: int`, `num_frames: int`, `duration_seconds: float`, `format: str` (e.g. "WAV"), `subtype: str` (e.g. "PCM_24")
   - `AudioFile` dataclass with fields: `waveform: torch.Tensor` (shape [channels, samples], float32), `sample_rate: int`, `metadata: AudioMetadata`

   **Functions:**
   - `is_supported_format(path: Path) -> bool`: Check if file extension is in SUPPORTED_FORMATS.
   - `get_metadata(path: Path) -> AudioMetadata`: Read metadata via `sf.info()` without loading waveform. Raise `FileNotFoundError` if path doesn't exist. Raise `ValueError` for unsupported formats.
   - `load_audio(path: Path, target_sample_rate: int = DEFAULT_SAMPLE_RATE) -> AudioFile`: Load audio via `sf.read(str(path), dtype="float32", always_2d=True)`, transpose from [samples, channels] to [channels, samples] via `torch.from_numpy(data.T)`. Resample to target_sample_rate if source differs using lazy-imported `torchaudio.transforms.Resample` (create resampler instance per unique source rate). Return AudioFile with waveform tensor and metadata.
   - `check_file_integrity(path: Path) -> tuple[bool, str]`: Try `sf.info()` then `sf.read()` of first 1024 frames. Return `(True, "OK")` on success, `(False, error_description)` on any exception. Check for 0-frame files.

   **Critical patterns:**
   - Use lazy imports for torch and torchaudio (import inside function bodies), matching Phase 1 pattern from hardware/device.py
   - Use `always_2d=True` in sf.read() so mono files return shape (N, 1) not (N,) -- avoids transpose bugs
   - Do NOT use torchaudio.load() (requires TorchCodec/FFmpeg in 2.10)
   - Do NOT use torchaudio.info() (removed in 2.10)
  </action>
  <verify>
Run `uv sync` succeeds. Then run:
```
uv run python -c "
from small_dataset_audio.audio.io import AudioFile, AudioMetadata, load_audio, get_metadata, is_supported_format, check_file_integrity, SUPPORTED_FORMATS
print('Imports OK')
print(f'Supported formats: {SUPPORTED_FORMATS}')
print(f'WAV supported: {is_supported_format(\"test.wav\")}')
print(f'TXT supported: {is_supported_format(\"test.txt\")}')
"
```
All imports succeed. WAV returns True, TXT returns False.
  </verify>
  <done>AudioFile and AudioMetadata dataclasses defined. load_audio loads via soundfile and returns [channels, samples] float32 tensor with optional resampling. get_metadata reads without loading waveform. check_file_integrity detects corrupt/empty files. No torchaudio.load() used anywhere.</done>
</task>

<task type="auto">
  <name>Task 2: Implement dataset validation with error collection pattern</name>
  <files>
    src/small_dataset_audio/audio/validation.py
    src/small_dataset_audio/audio/__init__.py
  </files>
  <action>
1. Create `src/small_dataset_audio/audio/validation.py` with:

   **Types:**
   - `Severity` enum with values `ERROR = "error"` and `WARNING = "warning"` (matching Phase 1's error/warning distinction from validation/environment.py)
   - `ValidationIssue` dataclass with fields: `severity: Severity`, `file_path: Path | None`, `message: str`

   **Functions:**
   - `validate_dataset(files: list[Path], min_file_count: int = 5) -> list[ValidationIssue]`: Orchestrates all validation checks and returns collected issues. Checks in order:
     a. **Minimum file count**: If `len(files) < min_file_count`, add ERROR issue (no file_path). If 0 files, return immediately.
     b. **Format support**: For each file, check `is_supported_format()`. Unsupported -> ERROR with file_path.
     c. **File integrity**: For each supported file, call `check_file_integrity()`. Corrupt -> ERROR with file_path.
     d. **Sample rate consistency**: For all valid files, call `get_metadata()`. If not all sample rates match the majority rate, add WARNING for each mismatched file (include detected rate and majority rate in message).
     e. **Empty/very short files**: Warn if any file is shorter than 0.1 seconds.
   - `collect_audio_files(directory: Path) -> list[Path]`: Recursively scan a directory for files with extensions in SUPPORTED_FORMATS. Return sorted list of Paths. Skip hidden files (starting with `.`). This supports the "import folder as dataset" requirement (DATA-02).
   - `format_validation_report(issues: list[ValidationIssue]) -> str`: Format issues into a human-readable string grouped by severity (errors first, then warnings), suitable for display. Use counts in header: "N errors, M warnings".

   **Critical patterns:**
   - Never raise exceptions during validation -- collect all issues and return them (Phase 1 pattern)
   - Wrap each per-file check in try/except to prevent one bad file from stopping validation of others
   - Import from audio.io for get_metadata, check_file_integrity, is_supported_format, SUPPORTED_FORMATS

2. Update `src/small_dataset_audio/audio/__init__.py` to re-export the public API:
   ```python
   from small_dataset_audio.audio.io import (
       AudioFile, AudioMetadata, load_audio, get_metadata,
       is_supported_format, check_file_integrity, SUPPORTED_FORMATS,
       DEFAULT_SAMPLE_RATE,
   )
   from small_dataset_audio.audio.validation import (
       validate_dataset, collect_audio_files, format_validation_report,
       ValidationIssue, Severity,
   )
   ```
   Use lazy imports (import inside __init__.py __getattr__ or direct imports are fine here since this is the public API module).
  </action>
  <verify>
Run:
```
uv run python -c "
from small_dataset_audio.audio.validation import validate_dataset, collect_audio_files, ValidationIssue, Severity
from pathlib import Path

# Test with empty list
issues = validate_dataset([], min_file_count=5)
assert len(issues) >= 1
assert any(i.severity == Severity.ERROR for i in issues)
print(f'Empty dataset: {len(issues)} issues')

# Test with nonexistent file
issues2 = validate_dataset([Path('/nonexistent/file.wav')], min_file_count=1)
assert any(i.severity == Severity.ERROR for i in issues2)
print(f'Missing file: {len(issues2)} issues')

# Test collect_audio_files on data/datasets (should return empty or gitkeep only)
files = collect_audio_files(Path('data/datasets'))
print(f'Collected files: {len(files)}')

# Test public API re-exports
from small_dataset_audio.audio import AudioFile, validate_dataset, Severity
print('Public API re-exports OK')
print('All validation tests passed')
"
```
All assertions pass. Public API accessible from `small_dataset_audio.audio`.
  </verify>
  <done>validate_dataset collects all issues (corrupt files, sample rate mismatches, format errors, insufficient count) without raising exceptions. collect_audio_files recursively finds supported audio files in a directory. audio/__init__.py re-exports the full public API from both io.py and validation.py.</done>
</task>

</tasks>

<verification>
1. `uv sync` installs soundfile, numpy, matplotlib without errors
2. `uv run python -c "import soundfile; print(soundfile.__version__)"` prints version >= 0.13.0
3. `uv run python -c "from small_dataset_audio.audio import AudioFile, AudioMetadata, load_audio, get_metadata, validate_dataset, collect_audio_files, Severity"` succeeds
4. All exports accessible from `small_dataset_audio.audio` namespace
5. No imports of `torchaudio.load`, `torchaudio.info`, or `torchcodec` anywhere in audio/ modules
</verification>

<success_criteria>
- soundfile, numpy, matplotlib added as dependencies and installed
- AudioFile/AudioMetadata dataclasses defined with correct field types
- load_audio returns [channels, samples] float32 tensor using soundfile (not torchaudio.load)
- get_metadata reads without loading waveform
- check_file_integrity detects corrupt/empty files per-file
- validate_dataset collects all issues without raising exceptions
- collect_audio_files finds supported files recursively in a directory
- audio/__init__.py re-exports full public API
</success_criteria>

<output>
After completion, create `.planning/phases/02-data-pipeline-foundation/02-01-SUMMARY.md`
</output>
