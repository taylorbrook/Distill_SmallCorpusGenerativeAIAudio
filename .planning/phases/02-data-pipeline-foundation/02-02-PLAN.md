---
phase: 02-data-pipeline-foundation
plan: 02
type: execute
wave: 2
depends_on: ["02-01"]
files_modified:
  - src/small_dataset_audio/audio/augmentation.py
  - src/small_dataset_audio/audio/preprocessing.py
autonomous: true

must_haves:
  truths:
    - "Augmentation pipeline applies pitch shift, time stretch, noise injection, and loudness variation"
    - "Each augmentation has independent probability (0.3-0.5), not all-or-nothing"
    - "Original unaugmented audio is always preserved alongside augmented copies"
    - "Augmentation expansion ratio is configurable (default 10x)"
    - "Preprocessing resamples all files to 48kHz target and normalizes to float32"
    - "Preprocessed tensors can be cached as .pt files for training reuse"
  artifacts:
    - path: "src/small_dataset_audio/audio/augmentation.py"
      provides: "Data augmentation pipeline with configurable transforms"
      exports: ["AugmentationPipeline", "AugmentationConfig"]
    - path: "src/small_dataset_audio/audio/preprocessing.py"
      provides: "Audio preprocessing for training (resample, normalize, chunk, cache)"
      exports: ["preprocess_for_training", "preprocess_dataset", "PreprocessingConfig"]
  key_links:
    - from: "src/small_dataset_audio/audio/augmentation.py"
      to: "torchaudio.transforms"
      via: "PitchShift, SpeedPerturbation, AddNoise, Vol transforms"
      pattern: "torchaudio\\.transforms"
    - from: "src/small_dataset_audio/audio/preprocessing.py"
      to: "src/small_dataset_audio/audio/io.py"
      via: "imports load_audio for file loading"
      pattern: "from.*audio\\.io import|from.*audio import"
    - from: "src/small_dataset_audio/audio/preprocessing.py"
      to: "src/small_dataset_audio/audio/augmentation.py"
      via: "imports AugmentationPipeline for dataset expansion"
      pattern: "from.*augmentation import|AugmentationPipeline"
---

<objective>
Data augmentation pipeline and preprocessing module -- enables the system to expand small datasets (5-500 files) through pitch shift, time stretch, noise injection, and loudness variation, then prepare audio for training.

Purpose: Small datasets (especially 5-20 files) require aggressive augmentation to produce enough training data. This plan creates the composable augmentation pipeline and the preprocessing pipeline that resamples, normalizes, augments, and optionally caches tensors as .pt files. These modules feed directly into Phase 3's training engine.

Output: `audio/augmentation.py` with configurable transform pipeline; `audio/preprocessing.py` with dataset preprocessing and caching.
</objective>

<execution_context>
@/Users/taylorbrook/.claude/get-shit-done/workflows/execute-plan.md
@/Users/taylorbrook/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-data-pipeline-foundation/02-RESEARCH.md
@.planning/phases/02-data-pipeline-foundation/02-01-SUMMARY.md
@src/small_dataset_audio/audio/io.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement composable augmentation pipeline</name>
  <files>
    src/small_dataset_audio/audio/augmentation.py
  </files>
  <action>
Create `src/small_dataset_audio/audio/augmentation.py` with:

**Configuration dataclass:**
- `AugmentationConfig` dataclass with fields:
  - `pitch_shift_probability: float = 0.5`
  - `pitch_shift_range: tuple[float, float] = (-2.0, 2.0)` (semitones)
  - `pitch_shift_n_fft: int = 2048` (larger for 48kHz to avoid bass artifacts -- research pitfall #6)
  - `speed_probability: float = 0.5`
  - `speed_factors: list[float] = field(default_factory=lambda: [0.9, 0.95, 1.0, 1.0, 1.05, 1.1])` (weighted toward 1.0)
  - `noise_probability: float = 0.3` (lower -- noise is more destructive)
  - `noise_snr_range: tuple[float, float] = (15.0, 40.0)` (dB)
  - `volume_probability: float = 0.5`
  - `volume_range: tuple[float, float] = (0.7, 1.3)` (amplitude multiplier)
  - `expansion_ratio: int = 10` (number of augmented copies per original)

**AugmentationPipeline class:**
- `__init__(self, sample_rate: int = 48000, config: AugmentationConfig | None = None)`:
  Store sample_rate and config (default to AugmentationConfig()). Pre-create reusable transform instances where possible to avoid per-call overhead (research anti-pattern). Specifically:
  - Pre-create SpeedPerturbation instance (takes sample_rate and factors at init)
  - Pre-create AddNoise instance (stateless, reusable)
  - Pre-create Vol will be created per-call since gain varies (but Vol is lightweight)
  - PitchShift: Create per-call since n_steps varies (PitchShift caches STFT kernels internally, but n_steps must be set at init)

- `augment(self, waveform: torch.Tensor) -> torch.Tensor`:
  Apply augmentations with independent probabilities. Each augmentation is gated by `random.random() < probability`. Order: pitch shift -> speed perturbation -> noise injection -> volume. Clamp output to [-1.0, 1.0] to prevent clipping. Return augmented waveform tensor (same shape convention: [channels, samples], though sample count may change from speed perturbation).

- `expand_dataset(self, waveforms: list[torch.Tensor]) -> list[torch.Tensor]`:
  For each input waveform, produce `config.expansion_ratio` augmented copies plus the original (unaugmented). Returns flat list: [original_1, aug_1_1, ..., aug_1_N, original_2, aug_2_1, ..., aug_2_N, ...]. Total output size = len(waveforms) * (1 + expansion_ratio).

**Critical patterns:**
- Lazy import torch and torchaudio.transforms inside __init__ and augment methods (Phase 1 pattern)
- Use `random.random()` for probability gating (standard Python random, not torch -- simpler and sufficient for augmentation decisions)
- n_fft=2048 for PitchShift at 48kHz (avoids bass artifacts per research pitfall #6)
- SpeedPerturbation returns (waveform, lengths) tuple -- only use waveform, discard lengths
- AddNoise requires noise tensor same shape as input -- generate with torch.randn_like()
- Clamp final output to [-1.0, 1.0] to prevent downstream issues
  </action>
  <verify>
Run:
```
uv run python -c "
import torch
from small_dataset_audio.audio.augmentation import AugmentationPipeline, AugmentationConfig

# Create pipeline
config = AugmentationConfig(expansion_ratio=3)
pipeline = AugmentationPipeline(sample_rate=48000, config=config)

# Create a fake 1-second mono waveform
waveform = torch.randn(1, 48000)

# Test single augmentation
augmented = pipeline.augment(waveform)
assert augmented.shape[0] == 1  # still mono
assert augmented.min() >= -1.0
assert augmented.max() <= 1.0
print(f'Single augment: input {waveform.shape} -> output {augmented.shape}')

# Test dataset expansion
expanded = pipeline.expand_dataset([waveform, waveform])
# 2 originals + 2*3 augmented = 8 total
assert len(expanded) == 2 * (1 + 3)
print(f'Expand dataset: 2 inputs -> {len(expanded)} outputs (expected {2*(1+3)})')
print('All augmentation tests passed')
"
```
Augmentation produces valid tensors clamped to [-1, 1]. Dataset expansion produces correct count.
  </verify>
  <done>AugmentationPipeline applies pitch shift, speed perturbation, noise injection, and loudness variation with independent probabilities. expand_dataset produces original + N augmented copies per input. PitchShift uses n_fft=2048 for 48kHz. Transforms are pre-created where possible.</done>
</task>

<task type="auto">
  <name>Task 2: Implement preprocessing pipeline with caching</name>
  <files>
    src/small_dataset_audio/audio/preprocessing.py
  </files>
  <action>
Create `src/small_dataset_audio/audio/preprocessing.py` with:

**Configuration dataclass:**
- `PreprocessingConfig` dataclass with fields:
  - `target_sample_rate: int = 48000` (project baseline)
  - `normalize: bool = True` (peak normalize to [-1, 1])
  - `cache_dir: str | None = None` (if set, cache preprocessed tensors as .pt files; if None, no caching)
  - `augment: bool = True` (whether to apply augmentation during preprocessing)
  - `augmentation_config: AugmentationConfig | None = None` (passed to AugmentationPipeline)

**Functions:**
- `preprocess_for_training(waveform: torch.Tensor, sample_rate: int, config: PreprocessingConfig) -> torch.Tensor`:
  Single-file preprocessing: resample to target_sample_rate if needed (using lazy-imported torchaudio.transforms.Resample), peak-normalize if config.normalize is True (divide by max abs value, handle silence by checking max > 0). Return preprocessed tensor [channels, samples].

- `preprocess_dataset(files: list[Path], config: PreprocessingConfig, progress_callback: Callable[[int, int, str], None] | None = None) -> list[torch.Tensor]`:
  Full dataset preprocessing pipeline:
  1. Load each file via `load_audio()` from audio.io (which already resamples to target_sample_rate)
  2. Apply peak normalization if config.normalize
  3. If config.augment, create AugmentationPipeline and call expand_dataset on all loaded waveforms
  4. If config.cache_dir is set, save each tensor as `{cache_dir}/{index:04d}.pt` using `torch.save()`. Create cache_dir if it doesn't exist.
  5. Call progress_callback(current_index, total_count, filename) after each file if provided
  6. Wrap each file load in try/except -- skip corrupt files, log warning, continue with valid files
  Return list of all tensors (originals + augmented if augmentation enabled).

- `load_cached_dataset(cache_dir: Path) -> list[torch.Tensor]`:
  Load all .pt files from cache_dir, sorted by filename. Return list of tensors. Raise FileNotFoundError if cache_dir doesn't exist or contains no .pt files.

- `clear_cache(cache_dir: Path) -> int`:
  Delete all .pt files in cache_dir. Return count of deleted files.

**Critical patterns:**
- Lazy import torch, torchaudio inside function bodies
- Import load_audio from audio.io -- do NOT use torchaudio.load
- Import AugmentationPipeline from audio.augmentation
- Wrap each per-file operation in try/except to handle corrupt files gracefully
- progress_callback is optional (None means silent) -- supports Phase 3 training UI integration
- Peak normalization: `waveform / waveform.abs().max()` but guard against all-zero (silent) files
  </action>
  <verify>
Run:
```
uv run python -c "
import torch
from pathlib import Path
from small_dataset_audio.audio.preprocessing import (
    preprocess_for_training, preprocess_dataset, load_cached_dataset, clear_cache,
    PreprocessingConfig,
)

# Test single-file preprocessing
config = PreprocessingConfig(target_sample_rate=48000, normalize=True, augment=False)
waveform = torch.randn(1, 48000) * 0.5  # half amplitude
processed = preprocess_for_training(waveform, 48000, config)
assert processed.abs().max() <= 1.0
assert processed.abs().max() > 0.9  # should be normalized close to 1.0
print(f'Preprocess single: max amplitude {processed.abs().max():.3f}')

# Test cache round-trip
import tempfile, os
with tempfile.TemporaryDirectory() as tmpdir:
    cache_path = Path(tmpdir) / 'cache'
    config_cached = PreprocessingConfig(cache_dir=str(cache_path), augment=False)
    # Save some tensors
    cache_path.mkdir()
    torch.save(torch.randn(1, 48000), cache_path / '0000.pt')
    torch.save(torch.randn(1, 48000), cache_path / '0001.pt')
    loaded = load_cached_dataset(cache_path)
    assert len(loaded) == 2
    count = clear_cache(cache_path)
    assert count == 2
    print(f'Cache round-trip: saved 2, loaded {len(loaded)}, cleared {count}')

print('All preprocessing tests passed')
"
```
Normalization works correctly. Cache save/load/clear round-trip succeeds.
  </verify>
  <done>preprocess_for_training handles resampling and normalization for single files. preprocess_dataset processes full file lists with optional augmentation, caching, and progress callbacks. load_cached_dataset loads .pt cache. clear_cache cleans up. Corrupt files are skipped gracefully.</done>
</task>

</tasks>

<verification>
1. `from small_dataset_audio.audio.augmentation import AugmentationPipeline, AugmentationConfig` succeeds
2. `from small_dataset_audio.audio.preprocessing import preprocess_for_training, preprocess_dataset, PreprocessingConfig` succeeds
3. AugmentationPipeline.augment produces tensors clamped to [-1, 1]
4. AugmentationPipeline.expand_dataset produces correct output count (inputs * (1 + expansion_ratio))
5. preprocess_for_training normalizes peak to ~1.0
6. Cache round-trip (save .pt, load .pt, clear) works correctly
7. No imports of torchaudio.load or torchaudio.info anywhere
</verification>

<success_criteria>
- AugmentationPipeline applies 4 augmentation types (pitch, speed, noise, volume) with independent probabilities
- PitchShift uses n_fft=2048 for 48kHz audio
- expand_dataset preserves originals alongside augmented copies
- Expansion ratio defaults to 10x, is configurable
- preprocess_dataset handles full file lists with error recovery per-file
- .pt caching works for preprocessed tensors
- Progress callback support for future UI integration
</success_criteria>

<output>
After completion, create `.planning/phases/02-data-pipeline-foundation/02-02-SUMMARY.md`
</output>
