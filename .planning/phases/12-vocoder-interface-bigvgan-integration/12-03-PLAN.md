---
phase: 12-vocoder-interface-bigvgan-integration
plan: 03
type: execute
wave: 3
depends_on:
  - 12-02
files_modified:
  - src/distill/vocoder/mel_adapter.py
  - src/distill/vocoder/bigvgan_vocoder.py
  - src/distill/vocoder/__init__.py
autonomous: false
requirements:
  - VOC-02
  - VOC-01
  - VOC-03
  - VOC-04
  - VOC-06

must_haves:
  truths:
    - "MelAdapter converts VAE log1p-HTK mels to BigVGAN log-clamp-Slaney mels correctly"
    - "BigVGANVocoder.mel_to_waveform accepts VAE-format mels [B, 1, 128, T] and returns waveforms"
    - "End-to-end pipeline produces audible, non-distorted waveform from VAE mel output"
    - "Vocoder inference works on the available device without errors"
  artifacts:
    - path: "src/distill/vocoder/mel_adapter.py"
      provides: "Mel format conversion from VAE to BigVGAN representation"
      exports: ["MelAdapter"]
    - path: "src/distill/vocoder/bigvgan_vocoder.py"
      provides: "Updated BigVGAN vocoder with integrated mel adapter"
    - path: "src/distill/vocoder/__init__.py"
      provides: "Updated public API with MelAdapter export"
      exports: ["VocoderBase", "BigVGANVocoder", "MelAdapter", "get_vocoder"]
  key_links:
    - from: "src/distill/vocoder/bigvgan_vocoder.py"
      to: "src/distill/vocoder/mel_adapter.py"
      via: "MelAdapter called inside mel_to_waveform before BigVGAN forward pass"
      pattern: "MelAdapter"
    - from: "src/distill/vocoder/mel_adapter.py"
      to: "vendor/bigvgan/meldataset.py"
      via: "Uses BigVGAN's mel_spectrogram function for Slaney mel computation"
      pattern: "mel_spectrogram|meldataset"
    - from: "src/distill/vocoder/mel_adapter.py"
      to: "src/distill/audio/spectrogram.py"
      via: "Uses AudioSpectrogram.mel_to_waveform for Griffin-Lim intermediate step"
      pattern: "AudioSpectrogram|mel_to_waveform"
---

<objective>
Implement the mel adapter that bridges the VAE's mel representation to BigVGAN's expected input format, completing the end-to-end vocoder pipeline.

Purpose: The mel adapter is the highest-risk component in the vocoder integration. The VAE produces log1p-normalized power mels with HTK filterbanks at 48kHz, while BigVGAN expects log-clamp-normalized magnitude mels with Slaney filterbanks at 44.1kHz. This plan implements the conversion, integrates it into BigVGANVocoder, and verifies the full pipeline produces quality audio.

Output: Working `MelAdapter` class, updated `BigVGANVocoder.mel_to_waveform()` that accepts VAE-format mels directly, and human-verified audio quality.
</objective>

<execution_context>
@C:/Users/Taylor/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/Taylor/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/12-vocoder-interface-bigvgan-integration/12-RESEARCH.md
@.planning/phases/12-vocoder-interface-bigvgan-integration/12-01-SUMMARY.md
@.planning/phases/12-vocoder-interface-bigvgan-integration/12-02-SUMMARY.md
@src/distill/audio/spectrogram.py
@src/distill/vocoder/bigvgan_vocoder.py
@src/distill/vocoder/mel_adapter.py
@vendor/bigvgan/meldataset.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement MelAdapter and integrate into BigVGANVocoder</name>
  <files>
    src/distill/vocoder/mel_adapter.py
    src/distill/vocoder/bigvgan_vocoder.py
    src/distill/vocoder/__init__.py
  </files>
  <action>
**Part A: Create MelAdapter**

Create `src/distill/vocoder/mel_adapter.py` implementing the mel format conversion.

Research recommends Approach C (hybrid transfer matrix) as primary with Approach A (waveform round-trip) as validation. However, Approach A is simpler, guaranteed correct, and the quality difference may be negligible since BigVGAN's neural reconstruction will clean up Griffin-Lim artifacts. Implement Approach A first, then evaluate whether Approach C is worth adding.

**Approach A implementation (waveform round-trip -- primary path):**

```python
"""Mel adapter: converts VAE mel representation to BigVGAN mel representation.

The VAE produces: log1p(power_mel_htk) at 48kHz
BigVGAN expects: log(clamp(magnitude_mel_slaney, 1e-5)) at 44.1kHz

Conversion strategy (waveform round-trip):
1. Undo log1p normalization -> power mel (HTK, 48kHz)
2. Reconstruct approximate waveform via Griffin-Lim (uses existing AudioSpectrogram)
3. Resample waveform 48kHz -> 44.1kHz
4. Compute BigVGAN-format mel using vendored meldataset.mel_spectrogram()

This approach is guaranteed to produce correct BigVGAN mels because
it uses BigVGAN's own mel computation on a real waveform. The Griffin-Lim
intermediate step introduces some quality loss, but BigVGAN's neural
reconstruction is robust to this.
"""
from __future__ import annotations

import logging
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    import torch

logger = logging.getLogger(__name__)
```

The `MelAdapter` class should:

1. **Constructor**: Accept a `SpectrogramConfig` (for the existing AudioSpectrogram) and the BigVGAN config (n_fft, hop_size, etc. from the vendored config.json). Create an `AudioSpectrogram` instance for the Griffin-Lim step. Create a `torchaudio.transforms.Resample(48000, 44100)` resampler.

2. **`convert(mel_vae: torch.Tensor) -> torch.Tensor` method**:
   - Input: VAE mel `[B, 1, 128, T]` in log1p format
   - Step 1: Use `AudioSpectrogram.mel_to_waveform()` to get approximate waveform `[B, 1, samples]` at 48kHz
   - Step 2: Resample to 44.1kHz using `torchaudio.transforms.Resample(48000, 44100)`
   - Step 3: Compute BigVGAN mel using vendored `meldataset.get_mel_spectrogram()` or the `mel_spectrogram()` function. Import via the same `sys.path` mechanism as BigVGANVocoder.
   - Output: BigVGAN mel `[B, 128, T']` in log-clamp format (T' may differ from T due to resampling)

3. **BigVGAN mel computation**: Use the vendored `meldataset.py` functions directly. The vendored code provides `get_mel_spectrogram(wav, h)` where `h` is an AttrDict config. Load the config from the BigVGAN model directory (same path returned by weight_manager).

4. **Device handling**: Griffin-Lim and InverseMelScale run on CPU (existing AudioSpectrogram behavior). Resampling can run on CPU too. The BigVGAN mel computation should also run on CPU for consistency. The final output tensor will be moved to the target device by BigVGANVocoder.

**Part B: Integrate MelAdapter into BigVGANVocoder**

Update `BigVGANVocoder.mel_to_waveform()` to:
1. Accept VAE-format mels `[B, 1, 128, T]` (the contract from VocoderBase)
2. Run them through `MelAdapter.convert()` to get BigVGAN-format mels
3. Move BigVGAN mels to the model's device
4. Run BigVGAN inference
5. Return waveform `[B, 1, samples]`

The MelAdapter should be created lazily on first `mel_to_waveform` call (not in `__init__`) to avoid loading AudioSpectrogram infrastructure until needed.

**Part C: Update __init__.py**

Add `MelAdapter` to the public API exports.

**IMPORTANT considerations:**
- The `mel_spectrogram` function in vendored `meldataset.py` uses a global dictionary `mel_basis` and `hann_window` for caching. This should work fine if called from a single process. Be aware of this pattern.
- The vendored code expects a config AttrDict with keys: `n_fft`, `num_mels`, `sampling_rate`, `hop_size`, `win_size`, `fmin`, `fmax`. Load these from the BigVGAN config.json or hardcode from the known values: `n_fft=2048, num_mels=128, sampling_rate=44100, hop_size=512, win_size=2048, fmin=0, fmax=None`.
- Per research: `fmax=None` means Nyquist (22050 Hz for 44.1kHz). The vendored mel_spectrogram handles this.
  </action>
  <verify>
- `python -c "from distill.vocoder.mel_adapter import MelAdapter; print('MelAdapter imported')"` succeeds
- `python -c "
import torch
from distill.vocoder import get_vocoder

v = get_vocoder('bigvgan')

# Create a dummy VAE-format mel [B, 1, 128, T] in log1p range
# Use small positive values typical of log1p(power_mel)
dummy_vae_mel = torch.rand(1, 1, 128, 20) * 5.0  # log1p values

wav = v.mel_to_waveform(dummy_vae_mel)
print(f'VAE mel: {dummy_vae_mel.shape} -> Waveform: {wav.shape}')
print(f'Waveform range: [{wav.min():.3f}, {wav.max():.3f}]')
print(f'Waveform is not all zeros: {wav.abs().sum() > 0}')
"` produces non-zero waveform output
- `python -c "from distill.vocoder import MelAdapter; print('export OK')"` confirms __init__.py updated
  </verify>
  <done>
MelAdapter converts VAE log1p-HTK mels to BigVGAN log-clamp-Slaney mels via waveform round-trip. BigVGANVocoder.mel_to_waveform() now accepts VAE-format mels [B, 1, 128, T] and returns waveforms [B, 1, samples]. The full pipeline runs without errors.
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Task 2: Verify vocoder audio quality</name>
  <files>test_bigvgan_output.wav</files>
  <action>
Generate a test audio file through the complete BigVGAN vocoder pipeline for human quality verification.

Run end-to-end test:
```python
import torch
from distill.vocoder import get_vocoder
from distill.audio.spectrogram import AudioSpectrogram

vocoder = get_vocoder("bigvgan")
spec = AudioSpectrogram()

# Generate a 1-second sine wave at 440Hz as test signal
t = torch.linspace(0, 1, 48000)
sine_wave = (torch.sin(2 * 3.14159 * 440 * t) * 0.5).unsqueeze(0).unsqueeze(0)
mel = spec.waveform_to_mel(sine_wave)

# Run through BigVGAN vocoder
wav_out = vocoder.mel_to_waveform(mel)

import torchaudio
torchaudio.save("test_bigvgan_output.wav", wav_out.squeeze(0), vocoder.sample_rate)
print(f"Saved test_bigvgan_output.wav (shape={wav_out.shape}, sr={vocoder.sample_rate})")
```

What was built: Complete BigVGAN vocoder pipeline: VAE mel -> MelAdapter -> BigVGAN -> waveform. The system automatically downloads BigVGAN weights (~489MB) on first use, converts VAE mel spectrograms to BigVGAN's expected format, and produces 44.1kHz audio output.

How to verify:
1. Listen to `test_bigvgan_output.wav` -- should be a clear 440Hz sine tone (A4 note)
2. Should NOT sound muffled, distorted, clicky, or underwater
3. Should NOT be silent or extremely quiet
4. Confirm the script ran without device errors
5. If first run, confirm BigVGAN weights downloaded with visible progress

Resume signal: Type "approved" if audio sounds correct, or describe any quality issues (muffled, distorted, silent, wrong pitch, etc.)
  </action>
  <verify>test_bigvgan_output.wav exists and plays audible audio</verify>
  <done>Human confirms BigVGAN vocoder output sounds correct -- clear, non-distorted, correct pitch</done>
</task>

</tasks>

<verification>
1. MelAdapter converts VAE mel [B, 1, 128, T] to BigVGAN mel [B, 128, T'] without error
2. BigVGANVocoder.mel_to_waveform accepts VAE-format mels and returns waveforms
3. End-to-end test produces audible, clear audio output
4. Output waveform is non-zero and in reasonable range
5. No device errors on the available platform
6. Human confirms audio quality is acceptable (not muffled, distorted, or silent)
</verification>

<success_criteria>
The complete VAE mel -> MelAdapter -> BigVGAN -> waveform pipeline produces clear, audible audio from a test signal, verified by human listening. The mel adapter correctly bridges the VAE's log1p-HTK representation to BigVGAN's log-clamp-Slaney representation.
</success_criteria>

<output>
After completion, create `.planning/phases/12-vocoder-interface-bigvgan-integration/12-03-SUMMARY.md`
</output>
