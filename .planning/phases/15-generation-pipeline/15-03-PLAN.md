---
phase: 15-generation-pipeline
plan: 03
type: execute
wave: 2
depends_on:
  - "15-01"
files_modified:
  - src/distill/cli/generate.py
autonomous: true
requirements:
  - CLI-04

must_haves:
  truths:
    - "distill generate MODEL --temperature 0.8 --top-k 50 --top-p 0.95 produces audio from a v2 VQ-VAE model with prior"
    - "Sampling flags (--temperature, --top-k, --top-p) are displayed in help output"
    - "Progress display shows chunk counter during multi-chunk generation"
    - "v1.0 slider/preset/blend flags warn or error when used with VQ-VAE models"
  artifacts:
    - path: "src/distill/cli/generate.py"
      provides: "Extended generate command with prior-based generation path and sampling flags"
      contains: "temperature"
  key_links:
    - from: "src/distill/cli/generate.py"
      to: "src/distill/inference/generation.py"
      via: "generate_audio_from_prior() call for VQ-VAE models"
      pattern: "generate_audio_from_prior"
    - from: "src/distill/cli/generate.py"
      to: "src/distill/models/persistence.py"
      via: "load_model_v2() for v2 VQ-VAE model loading"
      pattern: "load_model_v2"
---

<objective>
Extend the `distill generate` CLI command to detect VQ-VAE v2 models and use the prior-based generation path with --temperature, --top-k, and --top-p flags.

Purpose: Users need a CLI path for batch audio generation from trained priors with sampling controls. The existing CLI only handles v1.0 models.

Output: Extended cli/generate.py with VQ-VAE model detection, prior-based generation, and sampling control flags.
</objective>

<execution_context>
@C:/Users/Taylor/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/Taylor/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/15-generation-pipeline/15-RESEARCH.md
@.planning/phases/15-generation-pipeline/15-01-SUMMARY.md
@src/distill/cli/generate.py
@src/distill/cli/train_prior.py
@src/distill/cli/__init__.py
@src/distill/models/persistence.py
@src/distill/inference/generation.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Extend resolve_model to detect and load v2 VQ-VAE models</name>
  <files>src/distill/cli/generate.py</files>
  <action>
Modify the `resolve_model()` function in `src/distill/cli/generate.py` to detect and load v2 VQ-VAE models.

**Current behavior:** `resolve_model()` always calls `load_model()` (v1 only). For v2 VQ-VAE models, this raises an error because v2 models have `version=2` and `model_type="vqvae"`.

**New behavior:** Before calling `load_model()`, detect the model version by peeking at the saved file. If v2 VQ-VAE, use `load_model_v2()` instead.

Add a helper function `_detect_model_version(model_path: Path) -> tuple[int, str]`:
```python
def _detect_model_version(model_path: Path) -> tuple[int, str]:
    """Peek at a .distill file to detect version and model_type without full load.

    Returns (version, model_type) -- e.g. (1, "vae") or (2, "vqvae").
    """
    import torch
    saved = torch.load(model_path, map_location="cpu", weights_only=False)
    version = saved.get("version", 1)
    model_type = saved.get("model_type", "vae")
    return version, model_type
```

Update `resolve_model()`:
1. When loading from a direct `.distill` path, call `_detect_model_version()` first
2. If `version >= 2 and model_type == "vqvae"`, call `load_model_v2()` instead of `load_model()`
3. When loading from library lookup (UUID or name search), do the same detection on the resolved path
4. Change the return type annotation to `"LoadedModel | LoadedVQModel"` (union type)

Import `load_model_v2` and `LoadedVQModel` at the call site (lazy import inside the function).
  </action>
  <verify>
Run: `cd H:/dev/Distill-vqvae && python -c "from distill.cli.generate import resolve_model, _detect_model_version; print('resolve_model updated OK')"`
  </verify>
  <done>
resolve_model() detects v2 VQ-VAE models via _detect_model_version() and routes to load_model_v2(). Returns LoadedModel for v1, LoadedVQModel for v2.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add sampling flags and prior-based generation path to CLI generate</name>
  <files>src/distill/cli/generate.py</files>
  <action>
Extend the `generate()` command function in `src/distill/cli/generate.py`:

**Add new CLI flags** to the function signature (place after existing flags, before legacy options):

```python
# --- Prior sampling options (Phase 15) ---
temperature: float = typer.Option(
    1.0, "--temperature", "-t", help="Sampling temperature (0.1-2.0, higher = more diverse)"
),
top_k: int = typer.Option(
    0, "--top-k", help="Top-k sampling (0 = disabled, limits choices per step)"
),
top_p: float = typer.Option(
    0.9, "--top-p", help="Nucleus sampling threshold (0 = disabled, 0.9 = default)"
),
overlap_ms: float = typer.Option(
    50.0, "--overlap", help="Crossfade overlap in milliseconds for multi-chunk stitching"
),
```

**Add VQ-VAE model detection** in the single-model generation path (after `loaded = resolve_model(...)` in the `else` branch):

```python
from distill.models.persistence import LoadedVQModel

if isinstance(loaded, LoadedVQModel):
    # Prior-based generation for VQ-VAE models
    _generate_prior_cli(
        loaded=loaded,
        temperature=temperature,
        top_k=top_k,
        top_p=top_p,
        duration=duration,
        overlap_ms=overlap_ms,
        seed=seed,
        count=count,
        output_dir=output_dir,
        export_format=export_format,
        file_ext=file_ext,
        sample_rate=sample_rate,
        bit_depth=bit_depth,
        meta_overrides=meta_overrides,
        console=console,
        json_output=json_output,
    )
    return
```

**Warn on incompatible v1.0 flags** when VQ-VAE model is detected:
- If `slider is not None`: `console.print("[yellow]Warning:[/yellow] --slider is not supported for VQ-VAE models. Ignored.")`
- If `preset is not None`: `console.print("[yellow]Warning:[/yellow] --preset is not supported for VQ-VAE models. Ignored.")`
- If `blend is not None`: `console.print("[yellow]Warning:[/yellow] --blend is not supported for VQ-VAE models. Ignored.")`

**Create `_generate_prior_cli()` helper function:**

```python
def _generate_prior_cli(
    loaded, temperature, top_k, top_p, duration, overlap_ms, seed, count,
    output_dir, export_format, file_ext, sample_rate, bit_depth,
    meta_overrides, console, json_output,
):
```

Implementation:
1. Validate prior exists: if `loaded.prior is None`, print error and raise `typer.Exit(1)`
2. Print model info: `console.print(f"[green]Loaded VQ-VAE:[/green] {loaded.metadata.name} (prior: yes, device: {loaded.device.type})")`
3. Print sampling config: `console.print(f"[dim]temperature={temperature}, top_k={top_k}, top_p={top_p}, duration={duration}s[/dim]")`
4. Compute overlap_samples: `int(overlap_ms * 48)` (48 samples/ms at 48kHz)
5. Use Rich progress bar for chunk display (follow patterns from `cli/train_prior.py`):
   ```python
   from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn
   ```
6. Loop `count` times for batch generation:
   a. Set seed for this iteration: `current_seed = seed + i if seed is not None else None`
   b. Define progress_callback that updates Rich progress bar
   c. Call `generate_audio_from_prior(loaded, temperature, top_k, top_p, duration, overlap_samples, current_seed, progress_callback)`
   d. Export audio using existing `_export_result()` helper (construct a minimal GenerationResult-like object, or export directly with `export_audio()`)
   e. For export, use `export_audio()` directly from `distill.inference.export` since GenerationResult is v1.0-specific. Build sidecar JSON manually.
7. Output results as JSON or file paths per `json_output` flag.

For export, create a simpler export path since we don't have a v1.0 GenerationResult:
- Write sidecar JSON with `write_sidecar_json()` (model_name, seed, duration, sample_rate, generation config with temperature/top_k/top_p)
- Call `export_audio()` for the actual audio file
- Apply spatial processing via `_apply_spatial_post()` if spatial_mode is not mono

Import `generate_audio_from_prior` lazily inside the function.
  </action>
  <verify>
Run: `cd H:/dev/Distill-vqvae && python -c "from distill.cli.generate import generate; print('CLI generate import OK')"`
Run: `cd H:/dev/Distill-vqvae && python -m distill.cli generate --help 2>&1 | head -30` to verify --temperature, --top-k, --top-p flags appear in help.
  </verify>
  <done>
CLI generate command has --temperature, --top-k, --top-p, --overlap flags. VQ-VAE v2 models are detected and routed to prior-based generation. Incompatible v1.0 flags (--slider, --preset, --blend) warn when used with VQ-VAE models. Rich progress display shows chunk counter. Batch generation with --count works. Export uses existing infrastructure.
  </done>
</task>

</tasks>

<verification>
1. `python -c "from distill.cli.generate import generate"` -- import succeeds
2. `python -m distill.cli generate --help` shows --temperature, --top-k, --top-p flags
3. Grep for `generate_audio_from_prior` in cli/generate.py -- backend is called
4. Grep for `LoadedVQModel` in cli/generate.py -- model type detection exists
5. Grep for `_generate_prior_cli` in cli/generate.py -- prior generation path exists
</verification>

<success_criteria>
- `distill generate MODEL.distill --temperature 0.8 --top-k 50` works for v2 VQ-VAE models
- --temperature, --top-k, --top-p, --overlap flags appear in help output
- v1.0 models still work unchanged (regression check)
- v1.0-specific flags (--slider, --preset, --blend) warn when used with VQ-VAE models
- Rich progress bar shows chunk counter during generation
- Batch generation (--count N) increments seeds correctly
</success_criteria>

<output>
After completion, create `.planning/phases/15-generation-pipeline/15-03-SUMMARY.md`
</output>
