---
phase: 10-multi-format-export-spatial-audio
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - src/small_dataset_audio/inference/spatial.py
  - src/small_dataset_audio/audio/hrtf.py
  - src/small_dataset_audio/inference/stereo.py
autonomous: true

must_haves:
  truths:
    - "User can generate spatial stereo audio with configurable width and depth"
    - "User can generate binaural audio with HRTF-based spatialization for headphone listening"
    - "User can select output mode: stereo, binaural, or mono"
    - "Spatial controls (width + depth) adapt to the selected output mode"
    - "The old stereo_width parameter (Phase 4) is fully replaced by the new spatial system"
  artifacts:
    - path: "src/small_dataset_audio/inference/spatial.py"
      provides: "Spatial audio processing with stereo, binaural, and mono modes"
      contains: "class SpatialMode"
    - path: "src/small_dataset_audio/audio/hrtf.py"
      provides: "HRTF loading from SOFA files and binaural convolution"
      contains: "load_hrtf"
  key_links:
    - from: "src/small_dataset_audio/inference/spatial.py"
      to: "src/small_dataset_audio/audio/hrtf.py"
      via: "spatial.apply_spatial uses hrtf for binaural mode"
      pattern: "apply_binaural"
    - from: "src/small_dataset_audio/inference/spatial.py"
      to: "src/small_dataset_audio/inference/stereo.py"
      via: "spatial imports peak_normalize and create_dual_seed_stereo from stereo.py"
      pattern: "peak_normalize"
---

<objective>
Spatial audio system replacing Phase 4 stereo with width+depth controls and HRTF-based binaural rendering.

Purpose: Replace the simple stereo width parameter with a two-dimensional spatial system (width + depth) and add binaural output mode for immersive headphone listening. This is a core locked decision from the user.

Output: New `spatial.py` module with `SpatialMode` enum and `apply_spatial()` entry point; new `hrtf.py` module for SOFA file loading and binaural convolution; `sofar` dependency added.
</objective>

<execution_context>
@/Users/taylorbrook/.claude/get-shit-done/workflows/execute-plan.md
@/Users/taylorbrook/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/10-multi-format-export-spatial-audio/10-CONTEXT.md
@.planning/phases/10-multi-format-export-spatial-audio/10-RESEARCH.md
@src/small_dataset_audio/inference/stereo.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create hrtf.py for SOFA-based HRTF loading and binaural convolution</name>
  <files>
    pyproject.toml
    src/small_dataset_audio/audio/hrtf.py
    src/small_dataset_audio/audio/__init__.py
  </files>
  <action>
1. Add `sofar>=1.1` to project dependencies in `pyproject.toml`. Run `uv lock`.

2. Create `src/small_dataset_audio/audio/hrtf.py`:
   - Module docstring: "HRTF loading from SOFA files and binaural convolution for spatial audio."
   - Use lazy imports for sofar, scipy, numpy, torch/torchaudio (project pattern).

   - Add module-level `_hrtf_cache: dict[tuple[str, int], HRTFData] = {}` for caching loaded HRTF data by (sofa_path, sample_rate).

   - Add `HRTFData` dataclass:
     - `hrir_left: np.ndarray` -- Left ear impulse response [filter_length]
     - `hrir_right: np.ndarray` -- Right ear impulse response [filter_length]
     - `sample_rate: int` -- Sample rate of the HRIRs
     - `source_azimuth: float` -- Azimuth of the selected source position
     - `source_elevation: float` -- Elevation of the selected source position

   - Add `get_default_hrtf_path() -> Path`:
     - Returns the path to the bundled MIT KEMAR SOFA file.
     - Expected location: package data dir / "hrtf" / "mit_kemar.sofa"
     - Use `importlib.resources` or `Path(__file__).parent.parent / "data" / "hrtf" / "mit_kemar.sofa"` to locate.
     - If file does not exist, raise FileNotFoundError with clear message about downloading the HRTF file.

   - Add `load_hrtf(sofa_path: Path | None = None, target_sample_rate: int = 48_000, azimuth: float = 90.0, elevation: float = 0.0) -> HRTFData`:
     - If sofa_path is None, use get_default_hrtf_path().
     - Check _hrtf_cache for (str(sofa_path), target_sample_rate). Return cached if found.
     - Open SOFA file via `sofar.read_sofa(str(sofa_path))`.
     - Find nearest source position to (azimuth, elevation) using Euclidean distance on first two coords (azimuth, elevation) of `sofa.SourcePosition`.
     - Extract hrir_left = `sofa.Data_IR[nearest_idx, 0, :]` and hrir_right = `sofa.Data_IR[nearest_idx, 1, :]`.
     - If SOFA sample rate differs from target_sample_rate, resample HRIRs using torchaudio.transforms.Resample (project pattern, cache resampler).
     - Store in _hrtf_cache and return HRTFData.

   - Add `apply_binaural(mono: np.ndarray, hrtf: HRTFData, width: float = 1.0, depth: float = 0.5) -> np.ndarray`:
     - Convolve mono with hrir_left and hrir_right using `scipy.signal.fftconvolve(mono, hrir, mode='full')[:len(mono)]`.
     - Width control: blend between center `(left + right) * 0.5` and full binaural. `left_out = center + width * (left - center)`, same for right.
     - Depth control: apply simple proximity effect. Close (depth=0.0) adds bass boost via a 1st-order low-shelf filter (scipy.signal.butter or simple gain on low frequencies). Far (depth=1.0) applies gentle high-frequency rolloff. Intermediate depths interpolate. Use scipy.signal.sosfiltfilt with a low-shelf design. Keep simple for v1: just attenuate high frequencies proportional to depth (low-pass with cutoff scaling from 20kHz at depth=0 to ~8kHz at depth=1.0, using a gentle 1st-order Butterworth).
     - Return stereo array [2, samples] as float32.

   - Add `clear_hrtf_cache() -> None` to clear _hrtf_cache.

3. Update `src/small_dataset_audio/audio/__init__.py`:
   - Add import of `HRTFData`, `load_hrtf`, `apply_binaural` from `audio.hrtf`.
   - Add all three to `__all__`.

Note: The MIT KEMAR SOFA file needs to be downloaded and placed at `src/small_dataset_audio/data/hrtf/mit_kemar.sofa`. Create the directory structure. Download from `https://sofacoustics.org/data/database/mit/` -- the file `MIT_KEMAR_normal_pinna.sofa` (~1.4 MB). Create a script or instruction comment in hrtf.py noting the download location. For now, if the file is missing, load_hrtf should raise a clear FileNotFoundError with instructions.
  </action>
  <verify>
    Run: `uv run python -c "from small_dataset_audio.audio.hrtf import HRTFData, load_hrtf, apply_binaural; print('HRTF module OK')"` succeeds.
    Run: `uv run python -c "import sofar; print('sofar installed')"` succeeds.
  </verify>
  <done>
    hrtf.py loads HRTF data from SOFA files with caching. apply_binaural convolves mono audio with left/right HRIRs for binaural output with width and depth controls. sofar dependency added to pyproject.toml. MIT KEMAR SOFA file location documented.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create spatial.py replacing stereo system with stereo/binaural/mono modes</name>
  <files>
    src/small_dataset_audio/inference/spatial.py
    src/small_dataset_audio/inference/__init__.py
  </files>
  <action>
1. Create `src/small_dataset_audio/inference/spatial.py`:
   - Module docstring: "Spatial audio processing replacing Phase 4 stereo system. Provides stereo (mid-side widening with depth), binaural (HRTF-based), and mono output modes."
   - Lazy imports for numpy (project pattern).

   - Add `SpatialMode` enum (str, Enum):
     - `STEREO = "stereo"` -- mid-side stereo with width + depth
     - `BINAURAL = "binaural"` -- HRTF-based binaural for headphones
     - `MONO = "mono"` -- mono (no spatial processing)

   - Add `SpatialConfig` dataclass:
     - `mode: SpatialMode = SpatialMode.MONO` -- output mode
     - `width: float = 0.7` -- spatial width (0.0=mono center, 1.0=natural, up to 1.5=exaggerated)
     - `depth: float = 0.5` -- front-back depth (0.0=close/intimate, 1.0=distant/diffuse)
     - `validate()` method: check width in [0.0, 1.5], depth in [0.0, 1.0], mode is valid SpatialMode

   - Add `apply_spatial(mono: np.ndarray, config: SpatialConfig, sample_rate: int = 48_000) -> np.ndarray`:
     - If mode is MONO: return mono as-is (1-D array).
     - If mode is STEREO: call the existing `apply_mid_side_widening` from `inference.stereo` using config.width. Then apply depth as a proximity/distance effect: close (depth=0) emphasizes direct sound (no change), far (depth=1.0) adds a subtle diffuse character by mixing in a slightly delayed copy (room simulation). Keep depth implementation simple for stereo mode: use early reflection pattern -- mix original with a delayed copy scaled by depth*0.15 at ~25ms delay (similar to existing Haas effect but the delay is depth-dependent, ranging from 0ms at depth=0 to 40ms at depth=1.0). Return [2, samples].
     - If mode is BINAURAL: load HRTF via `audio.hrtf.load_hrtf()` (default SOFA, cached), then call `audio.hrtf.apply_binaural(mono, hrtf, width=config.width, depth=config.depth)`. Return [2, samples].
     - Always return float32 arrays.

   - Add `apply_spatial_to_dual_seed(left_mono: np.ndarray, right_mono: np.ndarray, config: SpatialConfig, sample_rate: int = 48_000) -> np.ndarray`:
     - For dual-seed stereo generation: applies spatial processing to pre-generated L/R channels.
     - If mode is MONO: average both channels and return 1-D.
     - If mode is STEREO: combine via `create_dual_seed_stereo` from stereo.py, then apply depth effect to the stereo result. Return [2, samples].
     - If mode is BINAURAL: combine to mono first (average), then apply binaural. Return [2, samples].

   - Add backward compatibility mapping function `migrate_stereo_config(stereo_mode: str, stereo_width: float) -> SpatialConfig`:
     - Maps old Phase 4 stereo_mode/stereo_width to new SpatialConfig:
       - "mono" -> SpatialConfig(mode=MONO)
       - "mid_side" -> SpatialConfig(mode=STEREO, width=stereo_width, depth=0.3)
       - "dual_seed" -> SpatialConfig(mode=STEREO, width=0.7, depth=0.3)
     - This preserves backward compatibility when loading old presets/history.

2. Update `src/small_dataset_audio/inference/__init__.py`:
   - Add import of `SpatialMode`, `SpatialConfig`, `apply_spatial`, `migrate_stereo_config` from `inference.spatial`.
   - Add all four to `__all__`.
   - Keep existing stereo.py imports (peak_normalize, create_dual_seed_stereo still used).

Note: Do NOT delete stereo.py -- it still provides `peak_normalize`, `create_dual_seed_stereo`, and `apply_mid_side_widening` which spatial.py uses. The replacement is at the API level (GenerationConfig will use SpatialConfig instead of stereo_mode/stereo_width in Plan 04).
  </action>
  <verify>
    Run: `uv run python -c "from small_dataset_audio.inference.spatial import SpatialMode, SpatialConfig, apply_spatial, migrate_stereo_config; print('Spatial module OK')"` succeeds.
    Run: `uv run python -c "from small_dataset_audio.inference import SpatialMode, SpatialConfig; print('Re-exports OK')"` succeeds.
    Run: `uv run python -c "from small_dataset_audio.inference.spatial import SpatialConfig, SpatialMode; c = SpatialConfig(mode=SpatialMode.STEREO, width=0.8, depth=0.4); c.validate(); print('Config validation OK')"` succeeds.
  </verify>
  <done>
    spatial.py provides SpatialMode enum (stereo/binaural/mono), SpatialConfig dataclass with width+depth, and apply_spatial dispatcher. Binaural mode uses HRTF convolution from hrtf.py. Stereo mode extends mid-side widening with depth control. migrate_stereo_config provides backward compatibility for old Phase 4 presets. stereo.py preserved for its utility functions.
  </done>
</task>

</tasks>

<verification>
1. `uv run python -c "from small_dataset_audio.inference.spatial import SpatialMode; assert SpatialMode.STEREO.value == 'stereo'; assert SpatialMode.BINAURAL.value == 'binaural'; assert SpatialMode.MONO.value == 'mono'; print('SpatialMode enum correct')"` -- passes
2. `uv run python -c "from small_dataset_audio.inference.spatial import migrate_stereo_config, SpatialMode; c = migrate_stereo_config('mid_side', 0.7); assert c.mode == SpatialMode.STEREO; print('Migration OK')"` -- passes
3. `uv run python -c "from small_dataset_audio.audio.hrtf import HRTFData; print('HRTF dataclass available')"` -- passes
4. `uv run python -c "import sofar; print('sofar dependency installed')"` -- passes
</verification>

<success_criteria>
- SpatialMode enum with STEREO, BINAURAL, MONO values
- SpatialConfig dataclass with mode, width (0.0-1.5), and depth (0.0-1.0)
- apply_spatial dispatches to correct processing for each mode
- Binaural mode uses HRTF convolution via scipy.signal.fftconvolve
- Stereo mode uses existing mid-side widening plus depth control
- HRTF loading from SOFA files with caching
- migrate_stereo_config maps old stereo_mode/stereo_width to new SpatialConfig
- Existing stereo.py functions preserved (peak_normalize, create_dual_seed_stereo)
</success_criteria>

<output>
After completion, create `.planning/phases/10-multi-format-export-spatial-audio/10-02-SUMMARY.md`
</output>
